This guide contains a description of the general workflow of a |||CRYO-EM||| project using |||SPHIRE||| 1.3.

It is based on the |||GUI||| of |||SPHIRE||| and demonstrates how to obtain high-resolution 3D maps of macromolecular complexes from |||CRYO-EM||| images.

It will direct you through all steps of |||SPANA||| based on a provided experimental data set.

After completing the tutorial, you should be able to independently process your own data.

In addition, almost every step contains a "**|||TIPCOLOR||||||TIPNAME|||**" section, with more advanced instructions that might help you to obtain the best results from your own data.

Optional steps, performed outside the |||GUI|||, as well as known issues of the version 1.3 release are described within info boxes.

|||NEWLINE|||

|||CENTER|||

A detailed |||SPHIRE||| documentation is available at:

|||NEWLINE|||

|||URL|||http://sphire.mpg.de|||URLEND|||

|||NEWLINE|||

There is a mailing list for user support, discussions and future announcements.

|||NEWLINE|||

You can subscribe at:

|||NEWLINE|||

|||URL|||https://listserv.gwdg.de/mailman/listinfo/sphire|||URLEND||| and search

the archives for your topic of interest.

|||NEWLINE|||

Once you have subscribed, you can also use the address:

|||NEWLINE|||

|||LISTMAIL|||

|||NEWLINE|||

to send e-mails to the |||SPHIRE||| team.

|||CENTEREND|||

|||TABLEOFCONTENT|||

|||CHAPTERGENERAL|||Software Installation|||CHAPTERNOLOGO|||

|||SECTION|||Install SPHIRE and MPI support|||SECTIONEND|||

To follow this guide and run |||SPHIRE||| you will need to properly install |||SPHIRE|||, either on a Linux computing cluster or a Linux multi-core desktop.

In both case an |||MPI||| installation is required.

Download |||SPHIRE||| at

|||NEWLINE|||

|||URL|||http://sphire.mpg.de/wiki/doku.php?id=howto:download\_latest|||URLEND|||

|||NEWLINE|||

and follow the instructions regarding |||SPHIRE||| and |||MPI||| installation.

It should be noted that |||SPHIRE||| and **EMAN2** \\parencite{Tang200738} are installed jointly, i.e., after installation of |||SPHIRE|||, **EMAN2** is also available and vice versa.

Note that |||SPHIRE||| requires |||MPI||| installation to use the most advanced commands, while **EMAN2** does not.

Both |||SPHIRE||| and **EMAN2** are issued under a joint BSD/GNU license (see the documentation) and are provided free of charge as a service to the scientific community.

|||NEWLINE|||

To make sure the installation completed successfully, open a terminal, type ***sphire***, hit the **Return** key and check if the |||SPHIRE||| |||GUI||| pops up.

To make sure the |||MPI||| installation finished successfully, type ***sp\_sx.py*** in

the terminal window and then type ***import mpi***.

If there are no error messages, exit the interactive mode by typing ***quit***.

Otherwise, it is advisable to contact either the local IT support or the |||SPHIRE||| team.

|||NEWLINE|||

|||SECTION|||Install crYOLO |||SECTIONEND|||

For particle selection from the digital micrographs, we will use the automated software **crYOLO**. Download **crYOLO** at

|||NEWLINE|||

|||URL|||http://sphire.mpg.de/wiki/doku.php?id=howto:download\_latest|||URLEND|||

|||NEWLINE|||

and follow the instructions. If you do not have access to a NVIDIA GPU, you can always download the CPU version of the program. The CPU version of **crYOLO** will perform approximately 6x slower.

|||SECTION|||Installation of associated EM Software Packages|||SECTIONEND|||

Alignment of direct detector movie frames is currently not included in |||SPHIRE|||.

However, within the framework of the |||GUI||| we provide a wrapper as a utility to **Unblur** \\parencite{Grant:2015kw}.

Please download the program **Unblur**

|||NEWLINE|||

(|||URL|||http://grigoriefflab.janelia.org/unblur|||URLEND|||, Grigorieff lab)

|||NEWLINE|||

and follow the installation instructions.

|||NEWLINE|||

For interactive visualization of the resulting structures, we use the molecular graphics program **UCSF CHIMERA** \\parencite{JCC:JCC20084} (|||URL|||https://www.cgl.ucsf.edu/chimera/download.html|||URLEND|||).

An extensive tutorial to get familiar with the features of **UCSF CHIMERA** can be found here:

|||URL|||https://www.cgl.ucsf.edu/chimera/data/tutorials/groel/groel.html|||URLEND|||

|||CHAPTERGREY|||PROJECT|||CHAPTERPROJECT|||

|||NEWLINE|||

In this tutorial, we use the |||SPHIRE||| |||GUI||| to determine a 3D |||CRYO-EM||| structure of the bacterial toxin component TcdA1 \\parencite{Gatsogiannis:2013} from a test dataset of 112 micrographs.

The images were collected on a |||CS|||-corrected FEI Titan Krios, operated at |||SI|||300 kilo volt|||SIEND||| and equipped with an |||XFEG||| and a Falcon II direct detector.

The digital micrographs have a pixel size of |||SI|||1.14 angstrom|||SIEND|||, and the particle is a pentameric assembly with C5 point group symmetry.

|||NEWLINE|||

First, create a **project directory** named **SPHIRE-demo**.

|||NEWLINE|||

|||TERMINAL|||

mkdir SPHIRE-demo

|||TERMINALEND|||

The **project directory** **SPHIRE-demo** will be created.

As it is necessary to **always start the |||SPHIRE||| |||GUI||| and run all project-associated commands from the project directory**, change to this directory:

|||NEWLINE|||

|||TERMINAL|||

cd SPHIRE-demo

|||TERMINALEND|||

Download the tutorial data.

At the terminal type (one long command):

|||NEWLINE|||

|||TERMINAL|||

wget --no-check-certificate\\\\ https://ftp.gwdg.de/pub/misc/sphire/test\_dataset/sphire\_testdata\_movies.tar

|||TERMINALEND|||

|||NEWLINE|||

(Alternatively, you can use your file browser to download the data from here:

|||NEWLINE|||

|||URL|||https://ftp.gwdg.de/pub/misc/sphire/test\_dataset/sphire\_testdata\_movies.tar|||URLEND|||)

|||NEWLINE|||

In order to extract the downloaded file, type:

|||NEWLINE|||

|||TERMINAL|||

tar -xvf sphire\_testdata\_movies.tar

|||TERMINALEND|||

|||NEWLINE|||

To launch the |||SPHIRE||| |||GUI|||, type:

|||NEWLINE|||

|||TERMINAL|||

sphire

|||TERMINALEND|||

|||NEWLINE|||

When |||SPHIRE||| is started for the first time, it will ask for permission to write a settings directory. Answer **y**. The main window will then appear.

|||NEWLINE|||

|||FIGUREGUI|||02\_gui.png|||FIGUREGUIEND|||

The column on the left contains several pictograms that allow you to select a particular step of the single particle image analysis workflow.

The first step is to provide the project-wide constant-value parameters.

These constants will be used as default values for the subsequent steps of the processing workflow.

|||NEWLINE|||

|||TIP|||

You can also skip registering these settings now, but in this case you will have to specify these standard parameters multiple times during the processing procedure.

|||TIPEND|||

|||NEWLINE|||

Click the ***PROJECT*** pictogram and fill out the following fields in the |||GUI||| interface that will appear:

|||NEWLINE|||

|||FIGUREGUI|||02\_gui\_project.png|||FIGUREGUIEND|||

|||NOTE|||

Clicking the gray button, next to the respective input field, retrieves a default value.

After the settings are registered here, they will become default values in the subsequent steps.

|||NOTEEND|||

|||ITEMIZEGUI|||

|||ITEM||| **Protein name:** TcdA1

|||ITEM||| **Micrograph pixel size \[A\]:** 1.14

|||ITEMTIP|||

Do not forget to adjust the pixel size if you have already binned your micrographs.

For example, micrographs recorded with the K2 in super-resolution mode have a very fine pixel size, and usually we bin them during the movie alignment before we start image processing in |||SPHIRE||| (see next section).

If you already aligned your movies and you wish to bin all micrographs for example two times (ratio of new to old image size=0.5), you can use bash batch processing:

|||TERMINAL|||

mkdir binned\_images

|||TERMINALEND|||

and afterwards (one long command)

|||TERMINAL|||

for file in $(ls \*.mrc);do sp\_process.py $\\{file\\} binned\_images/$\\{file\\}.mrc\\\\ --changesize --ratio=0.5; done

|||TERMINALEND|||

To bin a single micrograph, you can use the utility **Change Size of Image or Volume**

|||ITEMTIPEND|||

|||ITEM||| **|||CTF||| window size \[pixels\]:** 512

|||ITEMNOTE|||

Should be slightly larger than particle size

|||ITEMNOTEEND|||

|||ITEM||| **Particle box size \[pixels\]:** 352

|||ITEMNOTE|||

The particle box size should be at least |||SI|||1.5 times|||SIEND||| to |||SI|||2 times|||SIEND||| larger than the longest axis of the particle.

The long axis of the tutorial particle is |||SI|||25 nano meter|||SIEND||| (|||SI|||250 angstrom|||SIEND|||) and the pixel size is |||SI|||1.14 angstrom|||SIEND|||.

Thus, the long axis of the particle is |||SI|||250 angstrom|||SIEND||| / |||SI|||1.14 angstrom per pixel|||SIEND||| = |||SI|||220 pixel|||SIEND|||.

Here we set the box size to |||SI|||352 pixel|||SIEND|||, which corresponds to |||SI|||1.6 times|||SIEND||| the size of our particle.

|||ITEMNOTEEND|||

|||ITEMNOTE|||

The window size has to be an even number due to Fast Fourier Transform (FFT) requirements of some programs.

|||ITEMNOTEEND|||

|||ITEMTIP|||

If you recorded images at rather high defocus values (i.e., \> |||SI|||3 micro meter|||SIEND|||), you might want to consider using an even larger box size.

|||ITEMTIPEND|||

|||ITEM||| **Protein particle radius \[pixels\]:** 145

|||ITEMNOTE|||

Adjust this parameter carefully, so the radius set here will correspond to at least half of the longest axis of the particle.

|||ITEMNOTEEND|||

|||ITEMTIP|||

This value will be used to create a circular mask for data processing, both in 2D as well as in 3D.

Therefore, at the beginning of the project and especially if the center of the particle does not coincide with its center of mass, it might be preferable to use a slightly larger particle radius.

For globular complexes that can be easily centered, such as ribosomes, you should use a rather tight radius closely corresponding to the particle radius right from the beginning.

|||ITEMTIPEND|||

|||ITEM||| **Point-group symmetry:** C5

|||ITEMNOTE|||

If the point group symmetry of the particle is uncertain, do not assume symmetry and enter C1.

|||ITEMNOTEEND|||

|||ITEM||| **Protein molecular mass \[kDa\]:** 1400

|||ITEMNOTE|||

It can be approximate. The molecular mass of the protein is used for validation purposes in some steps of data processing.

|||ITEMNOTEEND|||

|||ITEM||| **Imaging configurations:** KRIOS Dortmund

|||ITEMNOTE|||

Your microscope name/configuration.

It is optional and is kept for record-keeping only.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Click the ***Register settings*** button, to register these values as defaults for all subsequent steps of the workflow, and then click the ***Save settings*** button, to save them in a text file.

This text file may be useful for entering information into your lab book or can be used to reload the settings if necessary.

A detailed description of the options is provided on our |||WIKI||| page.

Even if you do not save these settings now, registered parameters will be automatically displayed every time you start the |||GUI||| from the **project directory**.

|||NEWLINE|||

|||ADVANCED|||{Measuring the size of your particle}

Before collecting high-resolution movies, you most probably screened the quality of your sample by negative stain |||ELM||| and also possibly collected some |||CRYO-EM||| overview images.

You can use one of these images to measure the size of your particle using **e2display.py**.

|||ENUMERATE|||

|||ITEM||| Click the button ***UTILITIES*** on the left and then the Button ***Display Data*** in the middle to launch **e2display.py**.

|||ITEM||| Open an overview image with sufficient contrast.

|||ITEM||| Click the **mouse wheel button** somewhere on the image.

A pop-up window will appear.

|||ITEM||| Activate the ***Meas*** tab in the pop-up window, set the pixel size (A/Pix) and hit the **Return** key.

|||FIGUREADV|||02\_meas\_1.png|||FIGUREADVEND|||

|||ITEM||| Now identify the projection view of your particle with the largest size.

Keep the **left mouse button** pressed and draw a line to measure the longest axis of the particle.

The length of the line in |||UNIT|||angstrom|||UNITEND||| will be reported in the e2display.py pop up window (**Len**).

|||FIGUREADV|||02\_meas\_2.png|||FIGUREADVEND|||

|||ITEM||| To get the particle radius in pixels, divide the result by the pixel size:

|||EQUATION|||

\\text{Len in pixels} = \\frac{\\text{Length in angstrom}}{\\text{Pixel size}} = \\frac{256}{1.14} \\approx 112

|||EQUATIONEND|||

|||ENUMERATEEND|||

|||ADVANCEDEND|||

|||CHAPTERGREEN|||Movie|||CHAPTERMOVIE|||

|||SECTION|||Micrograph Movie Alignment|||SECTIONEND|||

Modern direct detectors record high-resolution images as movie frames.

Usually, we motion-correct the micrograph movies on the fly during image acquisition (using for example **tranSPHIRE**).

If motion-correction has not been performed yet, the first step in the workflow is the alignment of these frames for each image to correct the overall motion.

|||SPHIRE||| provides as a utility, a wrapper of the program **Unblur**, developed by the |||GRIGORIEFFLAB|||.

|||NEWLINE|||

|||TIP|||

Not all microscopes are equipped with cameras with movie capabilities, and generally only high-resolution projects require recording movie frames.

|||SPHIRE||| is very flexible in this respect and it is possible to skip certain steps of the workflow as long as the appropriate settings are entered.

This is critical when importing data created with different software packages.

Please read the |||TIPNAME||| section for each step of the workflow carefully and follow the instructions that best fit your processing scenario.

|||TIPEND|||

|||TIP|||

If you are not processing movies, you can directly copy the digital micrographs to a folder within the **project directory** and proceed directly to the ***CTER*** (\\nameref{CTF Estimation}) Section of the Tutorial.

|||TIPEND|||

|||TIP|||

If you already used **Unblur** or **MotionCor2** to align your movies, copy all results (including the logfiles) to the output folder **CorrectedSums** within the **project directory** and proceed to the next step.

|||TIPEND|||

|||TIP|||

If you are processing **negative stain** data, you can directly proceed to the ***WINDOW*** (\\nameref{Particle Extraction}) section of the Tutorial.

|||TIPEND|||

During unpacking of the tutorial data, a folder called **Movies** was created within the **project directory**.

To see the content of this folder, type:

|||TERMINAL|||

ls Movies/\*.mrc

|||TERMINALEND|||

This folder contains 112 low-dose movies of TcdA1 in the MRC file format.

|||NEWLINE|||

In the main window of the |||SPHIRE||| |||GUI||| click the button ***MOVIE*** on the lower left corner and then the ***Unblur cisTEM*** button in the middle.

An activated command button contains blue highlighted text.

|||FIGUREGUI|||03\_gui\_unblur.png|||FIGUREGUIEND|||

Fill out the following input fields:

|||ITEMIZEGUI|||

|||ITEM||| **unblur executable path:** /path/to/executable/unblur.exe

|||ITEMNOTE|||

Type here the path to the **Unblur** executable file or click the ***Select executable*** button to use your file browser to select it.

|||ITEMNOTEEND|||

|||ITEM||| **Input movie path pattern:** Movies/TcdA1-\*\_frames.mrc

|||ITEMNOTE|||

Click the ***Select MRC movie*** button, choose **MRC (\*.mrc)** as file type, and use the file browser to select a movie file.

Then replace the variable part of the file name with the wildcard character "\*".

In the case of this tutorial dataset, the variable part of the file name is only the serial number (**TcdA1-|||REDNUM|||0001|||REDNUMEND|||\_frames.mrc**).

|||ITEMNOTEEND|||

|||IMPORTANT|||

All movie files in a project must contain the same number of frames and have the same pixel size\!

|||IMPORTANTEND|||

|||ITEMTIP|||

It is preferable, but not necessary, to use serial numbers in file names that have the same number of digits (e.g. use mic\_0001.mrc, mic\_0010.mrc instead of mic\_1.mrc, mic\_10.mrc).

|||ITEMTIPEND|||

|||ITEM||| **Output directory:** CorrectedSums

|||ITEM||| **Movie selection file:** none

|||ITEM||| **Pixel size \[A\]:** 1.14

|||ITEM||| **Bin Factor:** 1.0

|||TIP|||

If you wish to bin the resulting motion-corrected averages, type the respective binning factor here. Afterwards, adjust the **Micrograph** **Pixel Size** in the **General Project Settings** accordingly. For example, if your movies have a pixel size of 0.6Å/pix and you set here a bin factor of 2, you would have to change the **Micrograph** **Pixel Size** parameter in the general settings to 1.2 Å/pix.

|||TIPEND|||

|||TIP|||

Expert users can also click the ***Advanced*** button to display the advanced settings.

However, the default values rarely need to be changed for standard projects, therefore these parameters will not be described in this tutorial.

|||TIPEND|||

|||IMPORTANT|||

Dose weighting is activated by default and can be deactivated in the advanced settings

|||IMPORTANTEND|||

|||ITEM||| **Microscope voltage \[kV\]:** 300.0

|||ITEM||| **Per-frame Exposure \[e/A^2\]:** 2.5

|||ITEMNOTE|||

Each movie of this dataset contains 24 frames with a total dose of |||SI|||60 electron per angstrom^2|||SIEND|||.

Thus, the per-frame exposure is

|||EQUATION|||

\\frac{\\text{Total dose}}{\\text{Number of movie frames}} = \\frac{|||SI|||60 electron per angstrom^2|||SIEND|||}{24} = |||SI|||2.5 electron per angstrom^2|||SIEND|||\\,.

|||EQUATIONEND|||

|||ITEMNOTEEND|||

|||ITEM||| **Pre-exposure \[e/A^2\]:** 0.0

|||ITEM||| **Create unadjusted sums in addition:** YES

|||TIP|||

Activate this option to additionally compute motion-corrected averages **without dose weighting**. These images will be required for the subsequent |||CTF||| estimation step.

|||TIPEND|||

|||ITEM||| **Gain File:** None

|||ITEMIZEGUIEND|||

Specify the number of processors (we used 24 for this job) and submit the job to the queuing system of the cluster using an appropriate submission file (see below) by clicking the ***Run command*** button.

|||IMPORTANT|||

Number of processors should always be lower than the total number of micrographs.

|||IMPORTANTEND|||

|||NEWLINE|||

A |||SGE||| template file can be found in your project directory (**msgui\_qsub.sh**).

You might need to configure or prepare a different template file for your own system.

If you are not familiar with your cluster and its queuing system, you should seek help from the system IT administrator in order to prepare the correct file.

Details about setting up the template file can be found on the |||SPHIRE||| wiki.

(|||URL|||http://sphire.mpg.de/wiki/doku.php?id=howto:submissions|||URLEND|||)

Monitor the progress of the job through the standard output. The name of the logfile containing the standard output depends on your submission file.

At the terminal, type:

|||TERMINAL|||

tail -f name\_of\_sp\_unblur\_logfile

|||TERMINALEND|||

|||STDOUT|||

main =\> 20.00% =\> Elapsed time: 0.87min | Estimated total time: 4.35min | Time per micrograph: 0.87min/mic

|||STDOUTEND|||

On our Linux cluster, using 24 processors, the alignment of the 112 movies required about |||SI|||6 minutes|||SIEND|||.

Otherwise, if you need to save time, you can copy the pre-calculated results to your **project directory** and continue with those.

To do so, type:

|||TERMINAL|||

cp -Rp SphireDemoResults/CorrectedSums ./

|||TERMINALEND|||

To see the content of the CorrectedSums output folder, type:

|||TERMINAL|||

ls CorrectedSums

|||TERMINALEND|||

The output folder contains following subfolders:

|||ITEMIZEDASH|||

|||ITEM||| **corrsum:** Contains the motion-corrected averages computed **without dose weighting**.

|||ITEM||| **corrsum\_dw:** Contains the motion-corrected, **dose-weighted** averages for all movie files

|||ITEM||| **corrsum\_dw\_log and corrsum\_log:** Contains the outputs of **Unblur**

|||ITEMIZEDASHEND|||

The motion-corrected averages computed without dose weighting are necessary for |||CTF||| estimation, whereas the dose-weighted averages will be used for all other steps of the workflow.

|||SECTION|||Drift Assessment|||SECTIONEND|||

Even after frame-alignment, some image averages still have a significant amount of drift (due to charging, holder instability or local grid damage) and some high-resolution information is lost.

The next step is to identify and exclude these images from the subsequent steps of the workflow.

For this purpose, we will analyze the results of **Unblur** using our **Drift Assessment GUI** tool (**sp\_gui\_unblur.py**) to select images with the lowest amount of drift.

|||NEWLINE|||

In the main window of the |||SPHIRE||| |||GUI||| first click the button ***MOVIE*** on the left and then the button ***Drift Assessment*** in the middle.

|||FIGUREGUI|||03\_gui\_assessment.png|||FIGUREGUIEND|||

Click the ***Select drift shift params*** button next to **Shift files,** and use the file browser to select one shift file (**CorrectedSums/corrsum\_dw\_log/TcdA1-0001\_frames.log**). Replace the micrograph number with the wildcard "\*" and then click the ***Run command*** button to open the |||GUI|||.

|||FIGUREGUI|||03\_assessment\_gui-01.png|||FIGUREGUIEND|||

|||TIP|||

The **Drift Assessment GUI** also supports analysis of **MotionCor2** shift files.

In this case, click the ***Select drift shift params*** button, and use the file browser to select one **MotionCor2** shift file (\*-Full.log file), replace the variable file name with the wildtype character "\*" and click the **Run command** button.

|||TIPEND|||

|||NEWLINE|||

Check the ***Overall Drift Histogram*** |||REDNUM|||(1)|||REDNUMEND||| checkbox.

On the plot for the overall drift (y-axis: number of micrographs, x-axis: overall drift in |||UNIT|||angstrom|||UNITEND|||) you can set a threshold to discard micrographs with an overall drift higher than a specific value (red line).

|||FIGURESUB|||03\_assessment\_hist\_1.png|||FIGURESUBMIDDLE|||03\_assessment\_hist\_2.png|||FIGURESUBEND|||

In the tutorial dataset, the average overall drift is |||SI|||2.77 angstrom|||SIEND||| (drift info for selected micrographs).

Right click the plot to set the discard threshold to roughly |||SI|||6 angstrom|||SIEND|||, in order to remove some outlier images.

|||NEWLINE|||

In order to register this threshold, click the ***Register*** button |||REDNUM|||(2)|||REDNUMEND|||.

|||FIGURESMALL|||03\_assessment\_gui\_register.png|||FIGURESMALLEND|||

Click ***Apply registered settings marked as criterion*** |||REDNUM|||(3)|||REDNUMEND||| and confirm the pop-up message box:

|||FIGURESMALL|||03\_assessment\_gui\_message\_box.png|||FIGURESMALLEND|||

Now type **Tutorial** as the prefix name for the output list files and click the ***Select output directory and save selection*** button |||REDNUM|||(4)|||REDNUMEND||| to specify an output directory (make a new folder with the name **DriftAssess**)

|||FIGUREGUI|||03\_assessment\_gui\_save.png|||FIGUREGUIEND|||

Four text files are then written to the folder **DriftAssess** in the **project directory**.

|||ITEMIZEDASH|||

|||ITEM||| **Tutorial\_selected.txt:** List of selected micrographs; 109 micrographs (|||SI|||97 percent|||SIEND|||)

|||ITEM||| **Tutorial\_discarded.txt:** List of discarded micrographs; 3 micrographs (|||SI|||2 percent|||SIEND|||)

|||ITEM||| **Tutorial\_shift\_selected.txt:** Shifts of selected micrographs

|||ITEM||| **Tutorial\_shift\_discarded.txt:** Shifts of discarded micrographs

|||ITEMIZEDASHEND|||

The average overall drift of the selected micrographs is now reduced to |||SI|||2.64 angstrom|||SIEND|||.

|||TIP|||

A more advanced usage of the **Drift Assessment GUI** is described on our |||WIKI||| page.

For example, if your dataset contains a sufficient number of micrographs, selecting the movies with the lowest drift rate during the first frames (drift per frame criterion) might also have a positive effect on the final resolution of the map.

|||TIPEND|||

|||CHAPTERGREEN|||CTER|||CHAPTERCTER|||

|||SECTION|||CTF Estimation|||SECTIONEND|||

The next step is to estimate the |||CTF||| parameters of the selected motion-corrected micrographs that are included in the list **Tutorial\_selected.txt**. Our CTF estimation tool is based on CTER (Automated estimation of |||CTF||| parameters with error assessment, \\parencite{Penczek:2014ji}). In addition to finding the parameters of the CTF, we will also perform extensive analysis of the quality of the fit and the reliability of individual parameters: defocus, astigmatism amplitude and angle, and, if selected, the phase shift. These error estimates allow you to automatically remove unreliable fits, which often are caused by the inferior quality of some micrographs. In doubtful cases the |||CTF||| assessment GUI makes it possible to review both the micrographs and CTF curves to gain more insight into the possible reasons of a poor fit. The most common causes are non-uniform micrograph fields (ice patches, contamination, mistakes with the electron dose) and/or defocus settings that are incompatible with other microscope settings or data sampling parameters (the so-called “Fourier aliasing” problems described in \\parencite{Penczek:2014ji}).

Note the |||CTF||| estimation will be performed exclusively on the micrographs averaged **without** dose-weighting.

In the main window of the |||SPHIRE||| |||GUI||| click the button ***CTER*** on the left and then the button ***CTF Estimation*** in the middle.

|||FIGUREGUI|||04\_gui\_estimation.png|||FIGUREGUIEND|||

Fill out the following fields:

|||ITEMIZEGUI|||

|||ITEM||| **Input micrograph path pattern:** CorrectedSums/corrsum/TcdA1-\*\_frames\_sum.mrc

|||ITEMNOTE|||

Click the ***Select MRC micrograph*** button, and use the file browser to select one of the motion-corrected averages computed **without** dose-weighting in the **corrsum** folder.

Then replace the variable part of the file name (the serial number) with the wildcard character "\*".

|||ITEMNOTEEND|||

|||ITEM||| **Output directory:** CTFEST

|||ITEM||| **Micrograph selection file:** DriftAssess/Tutorial\_selected.txt

|||ITEMNOTE|||

Click the ***Select micrograph list*** button, and use the file browser to load the list of selected micrographs created in the previous step.

|||ITEMNOTEEND|||

|||ITEM||| **Pixel size \[A\]:** 1.14

|||ITEM||| **Microscope spherical aberration (|||CS|||) \[mm\]:** 0

|||ITEMNOTE|||

The images of the tutorial dataset were collected on a |||CS|||-corrected Titan Krios

|||ITEMNOTEEND|||

|||ITEM||| **Microscope voltage \[kV\]:** 300.0

|||ITEM||| **Amplitude contrast \[%\]:** 10

|||ITEMTIP|||

Amplitude contrast is typically in the range of |||SI|||7 percent|||SIEND||| to |||SI|||14 percent|||SIEND|||.

|||SI|||10 percent|||SIEND||| yields good results for many projects in our lab.

|||ITEMTIPEND|||

|||ITEM||| **Lowest resolution \[A\]:** 40

|||ITEMNOTE|||

Low-resolution cut-off.

|||ITEMNOTEEND|||

|||ITEM||| **Highest resolution \[A\]:** 4

|||ITEMNOTE|||

High-resolution cut-off.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Advanced parameters:

|||ITEMIZEGUI|||

|||ITEM||| **Use PW Spectrum:** YES

|||ITEMIZEGUIEND|||

|||IMPORTANT|||

Activate this option only if Thon rings are unambiguously visible beyond |||SI|||4 angstrom|||SIEND||| in the power spectra of your micrographs.

|||IMPORTANTEND|||

Specify the number of processors (we used 96 for this job) and submit the job to the queuing system of the cluster using an appropriate submission file by clicking the ***Run command*** button.

|||IMPORTANT|||

Number of processors should be always lower than the total number of micrographs.

|||IMPORTANTEND|||

Monitor the progress of the job through the standard output. At the terminal, type:

|||TERMINAL|||

tail -f name\_of\_sp\_cter\_logfile

|||TERMINALEND|||

|||STDOUT|||

Micrographs processed by main process (including percent of progress):

|||NEWLINE|||

Processing CorrectedSums/corrsum/TcdA1-0001\_frames\_sum.mrc ---\> 0.00%

|||STDOUTEND|||

On our cluster, this process finished after about |||SI|||3 minutes|||SIEND|||.

However, if you do not have enough time to wait for the results, copy our pre-calculated results to your project directory.

|||TERMINAL|||

cp -r SphireDemoResults/CTFEST ./

|||TERMINALEND|||

Once the job has finished, the |||CTF||| results are stored in **CTFEST/partres.txt**.

A detailed explanation of the outputs and the format of the **partres.txt** file can be found on the |||SPHIRE||| wiki. (|||URL|||http://sphire.mpg.de/wiki/doku.php?id=pipeline:cter:sxcter|||URLEND|||) and in the ***CTER*** paper \\parencite{Penczek:2014ji}.

|||NEWLINE|||

Due to internal randomization of the statistical resampling procedure used to compute the CTF parameters and their standard deviation, results of different runs will differ slightly.

|||TIP|||

Open the output file (partres.txt) using a text editor and confirm that (a) the image defocus (column 1) is within the range used during data collection and that (b) its standard deviation (column 9) is low.

|||TIPEND|||

|||TIP|||

For |||CTF||| estimation of phase-plate data, activate the **Voltage Phase Plate Dataset** option found in the advanced settings and adjust the Defocus and phase shift search range and step according to your data collection settings.

|||TIPEND|||

|||SECTION|||CTF Assessment|||SECTIONEND|||

The |||CTF||| results are analyzed using the **CTF Assessment GUI** (**sp\_gui\_cter.py**).

This tool is used to assess the overall quality of the dataset and to identify and remove outliers that might have a negative impact on the final result.

This is accomplished by evaluating errors of |||CTF||| parameters estimated from the collected micrographs.

Micrographs for which the estimated |||CTF||| parameters are unreliable (i.e., have large errors) can be removed as they will not contribute any high-resolution information.  
The **CTF Assessment GUI** allows screening using multiple criteria simultaneously, which is particularly useful for the fast and effective analysis of large datasets.

|||NEWLINE|||

Here are examples of possible micrograph selection criteria to employ:

|||ITEMIZEARROW|||

|||ITEM||| Within a specific defocus range.

|||ITEMNOTE|||

If you aim to reconstruct a rather "large" particle, your dataset contains a sufficient number of images and image contrast is not an issue, then why would you keep far-from-focus images in your dataset?

They will not contribute high resolution information to the project.

|||ITEMNOTEEND|||

|||ITEM||| With low standard deviations regarding the defocus.

|||ITEMNOTE|||

A uniform defocus across the micrograph field is critical for near atomic resolution structure determination.

|||ITEMNOTEEND|||

|||ITEM||| With a certain frequency limit.

|||ITEMNOTE|||

Micrographs with unreliable |||CTF||| parameters and large defocus gradients, will most likely have a negative impact on the quality of the final map.

|||ITEMNOTEEND|||

|||ITEMIZEARROWEND|||

Elimination of low-quality micrographs reduces data processing time and improves the quality and resolution of the final structure.

|||NEWLINE|||

In this tutorial, we will only perform a simplified screening by setting thresholds for the defocus value and the astigmatism frequency limit (1st and 16th column in **partres.txt,** respectively).

Open the main window of |||SPHIRE||| |||GUI||| and click the button ***CTER*** on the left and then the button ***CTF Assessment*** in the middle.

|||FIGUREGUI|||04\_gui\_assessment.png|||FIGUREGUIEND|||

Click the ***Select CTER partres*** button, and use the file browser to select the |||CTF||| parameter file **partres.txt** in the **CTFEST** folder and click the ***Run command*** button to launch the |||GUI||| tool. Following windows will pop-up:

|||ITEMIZEDASH|||

|||ITEM||| **Control Panel**

|||ITEM||| **Histogram**

|||ITEM||| **Sort** **Plot**

|||ITEM||| **Fit Plot**

|||ITEMIZEDASHEND|||

This is the **Control Panel** window:

|||FIGUREGUI|||04\_assessment\_gui-01.png|||FIGUREGUIEND|||

First, check the **Sync. Sort** option |||REDNUM|||(1)|||REDNUMEND|||.

This will synchronize the selection of parameters in **Sort CTER Partres Entries** |||REDNUM|||(2)|||REDNUMEND||| and **Histogram & Plot Settings** |||REDNUM|||(3)|||REDNUMEND||| and their respective windows.

Now we will analyze the defocus distribution of this tutorial dataset.

Select **Defocus \[um\]** from the combo box |||REDNUM|||(3)|||REDNUMEND||| and check the **Sort Plot** and **Histogram** windows.

|||FIGUREMEDIUM|||04\_assessment\_sort.png|||FIGUREMEDIUMEND|||

|||FIGUREMEDIUM|||04\_assessment\_histogram\_1.png|||FIGUREMEDIUMEND|||

From both plots, we can see that the defocus of this dataset ranges from |||SI|||0.97 micro meter|||SIEND||| to |||SI|||2.25 micro meter|||SIEND|||.

To demonstrate the functionality of this tool, we will now discard all micrographs with a defocus value \> |||SI|||2.12 micro meter|||SIEND||| by setting the respective threshold.

Left click the Histogram window while clicking the SHIFT button to set the threshold at |||SI|||2.13 micro meter|||SIEND||| and a red dashed line will appear at the respective position.

Alternatively, you can set this threshold directly at the respective input field in the **Control Panel** window.

|||FIGUREMEDIUM|||04\_assessment\_histogram\_2.png|||FIGUREMEDIUMEND|||

|||TIP|||

You can also set a low cutoff-threshold in order to discard micrographs with a defocus lower than a specific value. In this case **left click** the **Histogram** window at the respective value and a blue dashed line will appear at the respective position.

|||TIPEND|||

|||NOTE|||

The **Sort plot** window supports the same mouse controls.

Usually, we use this approach to identify defocus "outliers" and/or select micrographs within a specific search range.

|||NOTEEND|||

In order to apply the user-defined defocus threshold, click the ***Apply All Thresholds*** |||REDNUM|||(4)|||REDNUMEND||| button.

A message dialog will pop up.

Click **Yes** to apply the threshold.

|||FIGURESMALL|||04\_assessment\_message\_box.png|||FIGURESMALLEND|||

|||NOTE|||

The respective outliers have now been unchecked in the micrograph list.

|||NOTEEND|||

You can see the number and ratio of the unchecked images in the **Selection Summary** |||REDNUM|||(7)|||REDNUMEND|||.

|||FIGURESMALL|||04\_assessment\_selection.png|||FIGURESMALLEND|||

|||TIP|||

You can also visually examine unchecked micrographs before discarding them.

To do so, activate the **Sort Select** checkbox under **Sort CTER Partres Entries**.

All unchecked micrographs will now be placed at the top of the micrograph list.

**Left click** an unchecked entry in the list to display the graphs and parameter values and click on the **Micrograph Thumbnail Checkbox (Display Windows)** to display the selected micrograph.

In the **Histogram** and **Sort Plot** windows, the green line indicates the value of the selected entry.

If you want to keep the selected micrograph, **check** the checkbox next to the file name in the micrograph list.

|||TIPEND|||

Now, we will use a second selection criterion to discard micrographs: **Astigm. Freq. Limit \[1/A\]**.

This parameter provides a good criterion to identify micrographs that have little high- resolution information content.

In the control panel, instead of **Defocus \[um\]**, select the **Astigm. Freq. Limit \[1/A\]** parameter from the combo box |||REDNUM|||(3)|||REDNUMEND||| and check again the **Histogram** and **Sort Plot** windows.

Using the procedure described above, set a low cut-off threshold at about |||SI|||0.33 1 per angstrom|||SIEND||| (=|||SI|||3 angstrom|||SIEND|||) and click again the **Apply All Thresholds** button |||REDNUM|||(4)|||REDNUMEND||| (the higher the limit of the astigmatism, the better the quality of the micrograph; thus, we want now to discard micrographs that have a limit below this threshold).

After applying this threshold, the low value cut-off (blue dashed line) should be at the following position in the Histogram plot:

|||FIGUREMEDIUM|||04\_assessment\_limit.png|||FIGUREMEDIUMEND|||

|||NOTE|||

The value of |||SI|||0.33 1 per angstrom|||SIEND||| corresponds to a resolution limit of |||SI|||1/0.33 angstrom|||SIEND||| = |||SI|||3 angstrom|||SIEND|||. Thus, in this case we will discard all micrographs that have an astigmatism resolution limit \> |||SI|||3 angstrom|||SIEND|||.

|||NOTEEND|||

|||TIP|||

You can also use other parameters to screen micrographs. However, from our experience **Astigm. Freq. Limit \[1/A\]** is the most convenient criterion to identify bad micrographs.

Thus, shifting the mean value of the **Astigm. Freq. Limit \[1/A\]** of your dataset to a higher value is likely to improve the final outcome.

Moreover, if you would prefer to discard micrographs with high amount of astigmatism, we recommend using the **Astig. Amp. \[um\]** criterion.

However, as long as Thon rings in images extend sufficiently far and the astigmatism estimations are precise, astigmatism is not *per se* detrimental to high-resolution work.

Finally, you should always remove micrographs whose |||CTF||| parameters have unusually high errors, meaning high standard deviations (|||SD||| of parameters).

|||TIPEND|||

At this point the number of unchecked micrographs increased from 1 to 2.

Enter "Tutorial" in **File Suffix** |||REDNUM|||(5)|||REDNUMEND||| under **Save Selection:** in the **Control Panel** and click the ***Save Selection*** button |||REDNUM|||(6)|||REDNUMEND|||.

A message dialog will pop up and inform you that following files are saved:

|||ITEMIZEDASH|||

|||ITEM||| **Tutorial\_micrographs\_select.txt:** List of selected Micrographs

|||ITEM||| **Tutorial\_ micrographs\_discard.txt:** List of discarded micrographs.

|||ITEM||| **Tutorial\_partres\_select.txt:** |||CTF||| parameters of the selected micrographs.

|||ITEM||| **Tutorial\_partres\_discard.txt:** |||CTF||| parameters of discarded micrographs.

|||ITEM||| **Tutorial\_thresholds.txt:** Applied thresholds.

|||ITEMIZEDASHEND|||

These files are stored in the location of the input |||CTF||| parameter file **partres.txt** in the folder **CTFEST**.

|||TIP|||

After this first selection step with the **CTF Assessment GUI**, it is possible to perform a second round of screening if necessary.

For this purpose, click the ***Open CTER partres file*** button |||REDNUM|||(8)|||REDNUMEND||| and load the |||CTF||| parameter file of the selected micrographs (**Tutorial\_partres\_select.txt**).

|||TIPEND|||

|||CHAPTERGREEN|||Window|||CHAPTERWINDOW|||

|||SECTION|||Particle Coordinates|||SECTIONEND|||

We will pick particles automatically using the **crYOLO** tool and store their coordinates. **crYOLO** is a “smart” particle picker based on convolutional neural networks, which utilizes the YOLO deep learning object detection approach. You can train **crYOLO** yourself, or you can use a general **crYOLO** model.

In order to train **crYOLO** you will need to pick several micrographs manually to create a model which is specific for your data. Alternatively, you can use the general |||SPHIRE||| network model instead, which was trained on more than 50 datasets and has already learned a sufficient set of generic features and allows **crYOLO** to pick the most datasets in a fully automated manner with high precision, with no need for any additional manual training.

Here we will perform reference-free particle picking with **crYOLO** in a fully- automated manner using the general model.

|||TIP|||

If your particle displays a “non-standard” shape not present in the general model and/or you wish to perform a “digital purification” during picking (e.g. train **crYOLO** to skip a certain particle population), it will be necessary to pick some micrographs manually and create your own training model.

|||TIPEND|||

An extensive tutorial to create your own training data and to get familiar with **all features** of **crYOLO** can be found here:

|||URL|||http://sphire.mpg.de/wiki/doku.php?id=pipeline:window:cryolo|||URLEND|||

|||IMPORTANT|||

For negative stain datasets, the standard general model will not work. Please download, and use the negative stain general model, instead.

|||URL|||https://sphire.mpg.de/wiki/doku.php?id=downloads:cryolo\_1\#for\_negative\_stain\_images|||URLEND|||

|||IMPORTANTEND|||

Now, in the main window of the |||SPHIRE||| |||GUI||| first click the button ***WINDOW*** on the left and then the ***crYOLO - predict*** button in the middle.

|||FIGUREGUI|||05\_gui\_coordinates.png|||FIGUREGUIEND|||

Fill out the following fields:

|||ITEMIZEGUI|||

|||ITEM||| **crYOLO predict executable:** /path/to/executable/cryolo\_predict.py

|||ITEMNOTE|||

Type here the path to the **crYOLO\_predict.py** executable file or click the ***Select python file*** button to use your file browser to select it.

|||ITEMNOTEEND|||

|||ITEM||| **Config file:** config.json

|||ITEMNOTE|||

Click the ***Select JSON file*** button, and use the file browser to load the **crYOLO** configuration file

|||ITEMNOTEEND|||

|||ITEMTIP|||

When you process your own data, it is necessary to edit the config.json file and set the value in the “anchors” field to your desired box size (pixels). This size has to completely enclose the longest axis of your particle.

|||ITEMTIPEND|||

|||ITEM||| **Image Directory:** CorrectedSums/corrsum\_dw

|||ITEMNOTE|||

Click the ***Select directory*** button, and use the file browser to choose the directory containing the **dose-weighted** motion-corrected averages.

|||ITEMNOTEEND|||

|||ITEM||| **Model path**: CRYOLO\_FILES/gmodel\_phosnet\_201900909.h5

|||ITEMNOTE|||

Click the ***Select h5 file*** button. and use the file browser to choose the general training model.

|||ITEMNOTEEND|||

|||ITEMTIP|||

Please use the latest version of the general model, since we regularly add additional handpicked datasets.

|||URL|||https://sphire.mpg.de/wiki/doku.php?id=downloads:cryolo\_1\#for\_cryo\_images\_low-pass\_filtered|||URLEND|||

|||ITEMTIPEND|||

|||ITEM||| **Output Directory:** Coordinates

|||ITEMIZEGUIEND|||

and submit the job to the queuing system of the cluster using an appropriate submission script by clicking the ***Run command*** button.

Monitor the progress of the job through the standard output. At the terminal, type:

|||TERMINAL|||

tail -f name\_of\_sp\_cryolo\_predict\_logfile

|||TERMINALEND|||

|||TIP|||

**CrYOLO** filters the digital micrographs prior particle selection to a resolution of |||SI|||30 angstrom|||SIEND|||.

|||TIPEND|||

|||STDOUT|||

Filtering CorrectedSums/corrsum\_dw/TcdA1-0191\_frames.mrc

|||NEWLINE|||

134 particles are found in tmp\_filtered/CorrectedSums/corrsum\_dw/TcdA1-0126\_frames.mrc ( 0 % )|||STDOUTEND|||

On our cluster, this process finished on a single processor after about |||SI|||9 minutes|||SIEND|||.

However, if you do not have enough time to wait for the results, simply copy our pre-calculated results to your project.

|||TERMINAL|||

cp -r SphireDemoResults/Coordinates ./

|||TERMINALEND|||

The output folder **Coordinates** within the project directory will include following subfolders:

|||ITEMIZEDASH|||

|||ITEM||| **EMAN:** this folder includes a particle coordinate file for every micrograph in the EMAN1 .box file format.

|||ITEM||| **STAR:** here you can find the coordinate files in the STAR file format.

|||ITEM||| **CBOX:** The format here is similar to EMAN1’s .box file format, but these files contain an additional column for the confidence score for each particle during picking. You can use these scores to fine-tune your particle picking (see description below).

|||ITEMIZEDASHEND|||

Now we will use **crYOLO**’s boxmanager to display the picking results. In the main window of the |||SPHIRE||| |||GUI|||, the button ***Window*** on the left and then the button ***crYOLO - boxmanager*** in the middle (under the section Utilities).

Fill out the following fields:

|||ITEMIZEGUI|||

|||ITEM||| **crYOLO boxmanager executable:** /path/to/executable/cryolo\_boxmanager.py

|||ITEMNOTE|||

Type here the path to the **crYOLO\_boxmanager.py** executable file or click the ***Select python file*** button to use the file browser to select it.

|||ITEMNOTEEND|||

|||ITEM||| **Input image directory:** CorrectedSums/corrsum\_dw/

|||ITEMNOTE|||

Click the ***Select directory*** button, and use the file browser to select the directory containing the **dose-weighted** motion-corrected micrographs

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Click the ***Run command*** button to launch the **crYOLO box manager** |||GUI||| tool.

Click on the **File** tab and then select the **Import box files** option. Use the file browser to select the **CBOX** folder within the **Coordinates** directory to load the coordinates for each micrograph.

|||FIGUREGUI|||05\_gui\_cryolo\_01.png|||FIGUREGUIEND|||

Here it is possible to adjust the confidence threshold using the slider button and the live preview in order to filter your particle boxes and to exclude (or include) additional particles.

|||FIGUREGUI|||05\_gui\_cryolo\_02.png|||FIGUREGUIEND|||

|||TIP|||

An animated GIF showing how to filter particle boxes using the **crYOLO** box manager can be found on the **|||SPHIRE|||** wiki:

|||URL|||http://sphire.mpg.de/wiki/lib/exe/detail.php?id=pipeline%3Awindow%3Acryolo\&media=pipeline:window:ezgif-1-3b966b0324d1.gif|||URLEND|||

|||TIPEND|||

For this dataset, particle picking with the default parameters worked well, and therefore it is not necessary to fine-tune the confidence threshold or repeat the picking procedure using a hand-picked training model.

|||TIP|||

If you picked your micrographs with a different particle picking utility, copy the co-ordinate files to the **Coordinates** folder and continue from there. It is not necessary to use the tutorial naming convention. We prefer using the **EMAN1** coordinate file format (.box), but |||SPHIRE||| also supports coordinates from **EMAN2** and **SPIDER** with the .json and .spi extension, respectively. If **RELION** coordinate files are available (.star), you can easily convert them to the **EMAN1** file format (.box) using the **sp\_relion2sphire** utility. For this purpose, in the main window of the |||SPHIRE GUI||| click the pictogram **UTILITIES** on the left and then the **RELION to SPHIRE conversion** button in the middle. Detailed instructions are provided in the **Import a star file page** of the wiki. |||URL|||http: //sphire.mpg.de/wiki/doku.php?id=howto:relion2sphire |||URLEND|||

|||TIPEND|||

|||SECTION|||Particle Extraction|||SECTIONEND|||

In the main window of the |||SPHIRE||| |||GUI|||, click the button ***WINDOW*** on the left and then the **Particle Extraction** button in the middle.

|||FIGUREGUI|||05\_gui\_extraction.png|||FIGUREGUIEND|||

Fill out the following input fields at the |||GUI||| interface:

|||ITEMIZEGUI|||

|||ITEM||| **Input micrograph path pattern:** CorrectedSums/corrsum\_dw/TcdA1-\*\_frames.mrc

|||ITEMNOTE|||

Click the ***Select MRC micrograph*** button, and use the file browser to select one of the micrographs in the **CorrectedSums/corrsum\_dw** folder.

Replace the variable part of the file name with the wildcard character “\*” (e.g. from **TcdA1-0010\_frames\_sum.mrc** to **TcdA1-\*\_frames\_sum.mrc**).

|||ITEMNOTEEND|||

|||ITEMTIP|||

If the micrographs are from negative stain and the particle coordinates are available, one can start directly with particle extraction and skip all previous steps.

In this case, insert **the/path/to/your/micrographs/\*.mrc** here instead.

|||ITEMTIPEND|||

|||ITEM|||**Input coordinates path pattern:** Coordinates/EMAN/TcdA1-\*\_frames.box

|||ITEMNOTE|||

Click the ***Select BOX coordinates*** button, and use the file browser to select one of the coordinate files in the **Coordinates/EMAN** folder.

Replace the variable part of the file name with the wildcard character “\*” (i.e., from **TcdA1-0010\_frames\_sum.box** to **TcdA1-\*\_frames\_sum.box**).

In this demo, the folder **Coordinates/EMAN** contains 101 *.box* files.

|||ITEMNOTEEND|||

|||ITEMTIP|||

It is not necessary to use the same root names for micrographs and coordinates files.

However, the variable part defined by the wildcard character **needs to** **be** identical for the association of the **input micrograph** and **coordinate file**.

|||ITEMTIPEND|||

|||ITEM||| **|||CTF||| parameters source:** CTFEST/Tutorial\_partres\_select.txt

|||ITEMNOTE|||

Click the **Select CTER partres** button, and use the file browser to select the **tutorial\_partres\_select.txt** file in the **CTFEST** folder.

This file contains the |||CTF||| parameters of the **selected** micrographs.

The |||CTF||| information will be transferred to the header of all extracted particles from their respective micrograph.

|||ITEMNOTEEND|||

|||ITEMTIP|||

If you process negative stain data, do not provide the |||CTF||| parameter source file here, but instead type the pixel size of your micrographs.

In this case, the program will include an “ideal” |||CTF||| (no modulation of the signal; |||SI|||90 degree|||SIEND||| phase shift; defocus |||SI|||0 micro meter|||SIEND|||) to the header of the extracted particles.

|||ITEMTIPEND|||

|||ITEM||| **Output directory:** Particles

|||ITEM||| **Micrograph selection file:** CTFEST/Tutorial\_micrographs\_select.txt

|||ITEMNOTE|||

Click the ***select micrograph list*** button, and use the file browser to select the **tutorial\_micrographs\_select.txt** file (list of selected micrographs) in the **CTFEST** folder.

|||ITEMNOTEEND|||

|||ITEMTIP|||

If you process negative stain data and/or skipped the micrograph selection steps, leave this field empty.

|||ITEMTIPEND|||

|||ITEM||| **Coordinate file format:** cryolo

|||ITEMNOTE|||

Additional supported file formats are **EMAN1** (*.box*), **EMAN2** (*.json*), and **SPIDER** (*.spi*).

|||ITEMNOTEEND|||

|||ITEM||| **Particle box size \[Pixels\]:** 352

|||ITEM||| **Invert image contrast:** YES

|||ITEMNOTE|||

For typical |||CRYO-EM||| data (particles appear dark on a bright background), leave this flag as it is.

The program will invert the contrast of your |||CRYO-EM||| images automatically.

|||ITEMNOTEEND|||

|||ITEMNOTE|||

If your particles appear bright on a dark background (e.g. negative stain or inverted cryo-EM images), deactivate this flag.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Specify the number of processors (we used 48) and submit the job to the queuing system of the cluster using an appropriate submission script by clicking the ***Run command*** button.

Monitor the progress of the job through the standard output.

|||STDOUT|||

TcdA1-0010\_frames.mrc ---\> 0.00%

|||NEWLINE|||

TcdA1-0011\_frames.mrc ---\> 50.00%

|||NEWLINE|||

Summary of micrograph level processing...

Valid : 107

|||NEWLINE|||

Processed : 107

|||NEWLINE|||

Rejected by no coordinates entries : 0

|||NEWLINE|||

Global summary of coordinates level processing...

|||NEWLINE|||

Detected : 12658

|||NEWLINE|||

Processed : 12658

|||NEWLINE|||

Rejected by out of boundary : 0

|||NEWLINE|||

Please execute from the command line : e2bdb.py Particles/mpi\_proc\_\* --makevstack=bdb:Particles\#data

|||NEWLINE|||

DONE\!\!\!

|||NEWLINE|||

|||STDOUTEND|||

However, if there is no time to wait for the results, copy our precalculated results to your **project directory**.

|||TERMINAL|||

cp -Rp SphireDemoResults/Particles ./

|||TERMINALEND|||

Once the job has finished, the extracted particles are stored in the folder Particles.

For each processed micrograph, extracted particle images are stored in an independent |||BDB||| data file.

On our cluster, this step completed in about |||SI|||1 minute|||SIEND|||.

|||SECTION|||Particle Stack|||SECTIONEND|||

The next step is to combine the individual per-micrograph stacks into a single “virtual” particle stack.

|||IMPORTANT|||

Skip this step if you used only a single processor to extract particles.

|||IMPORTANTEND|||

We call this stack "virtual" since, taking advantage of **EMAN2**’s |||BDB||| format, it contains **only** metadata (header information associated with images, such as pixel size, particle micrograph origin, any alignment parameters) and links to the original images.

In this way we minimize disk space usage while affording great flexibility with rapid creation of particle data stacks as necessary in subsequent data processing steps.

|||TIP|||

|||BDB||| files reside in separate directories, always named **EMAN2DB**.\\\\

An **EMAN2DB** directory that is not linked to any other |||BDB||| directory (through the virtual stack mechanism) can be easily archived, copied and transferred.

However, directories linked through the virtual stack mechanism have to be copied jointly while preserving relative directory structure.

It is very important not to modify **EMAN2DB** directories content in any way as this usually results in irreversible loss of information.

|||TIPEND|||

In the main window of the |||SPHIRE||| |||GUI||| click the button ***WINDOW*** on the left and then the ***Particle Stack*** button in the middle.

|||FIGUREGUI|||05\_gui\_stack.png|||FIGUREGUIEND|||

Fill out the following input fields:

|||ITEMIZEGUI|||

|||ITEM||| **Output virtual image stack:** bdb:Particles/stack

|||ITEMNOTE|||

This defines the **Particles** folder as destination for the virtual stack.

|||ITEMNOTEEND|||

|||ITEM||| **Input BDB image stack pattern:** Particles/mpi\_proc\_\*

|||ITEMNOTE|||

Click the ***Select directory*** button, and use the file browser to select folder **Particles** and then one of the **mpi\_proc** folders, which includes particle stacks for micrograph files extracted from a specific processor.

Replace the variable part of the name of the folder by the wildcard character “\*” (i.e., **mpi\_proc\_000** to **mpi\_proc\_\***).

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Click the ***Run command*** button to create the stack and monitor the progress of this job through the standard output.

This step is usually finished in a few seconds.

|||NEWLINE|||

After the job is finished, you can verify the number of particles in the resulting stack using **EMAN2**’s **e2iminfo.py** command.

|||NEWLINE|||

At the terminal, type:

|||TERMINAL|||

e2iminfo.py bdb:Particles/stack

|||TERMINALEND|||

Depending on the settings you used during particle picking (confidence threshold), the dataset processed here should contain about 8500 to 12000 single particles.

The stack in the pre-calculated results contains 12658 particles.

|||NEWLINE|||

You can also display the virtual stack using the utility **Display Data**.

For this purpose, in the main window of the |||SPHIRE||| |||GUI||| click the ***Display Data*** button in the middle, and load the stack.

However, please keep in mind that the display of a very large particle stack might result in a memory crash.

|||CHAPTERGREEN|||ISAC|||CHAPTERISAC|||

|||SECTION|||2D Clustering|||SECTIONEND|||

The 2D classification is one of the crucial steps of the workflow.

It will quickly give you a good idea about the quality and heterogeneity of the data and is a great tool to sort out bad particles.

Thus, it is a key step towards a high-resolution structure determination.

In other packages, this is usually done via computationally expensive 3D classifications, which usually have to be performed multiple times.

In contrast, we prefer to conduct 3D analysis using datasets that were pre-cleaned in 2D and, as a result, we usually need to perform heterogeneity analysis in 3D only once.

|||NEWLINE|||

|||SPHIRE||| uses the **ISAC** method \\parencite{Yang:2012dv} to perform 2D alignment and clustering in order to determine validated and homogeneous subsets of images with minimal human intervention.

Due to the high number of reproducibility tests during the validation procedure, **ISAC** used to be (pre-2016 version) very time- and memory-consuming.

The current, optimized **ISAC2** version delivers results for data sets of up to 700000 and it is |||SI|||10 times|||SIEND||| to |||SI|||15 times|||SIEND||| faster than the pre-2016 version.

|||NEWLINE|||

The ISAC program will:

|||ITEMIZEARROW|||

|||ITEM||| Phase-flip the 2D images in the stack, if requested.

|||ITEM||| Establish initial translation parameters using a reference-free approach, if requested.

|||ITEM||| Perform equal size K-means clustering, run a group stability test and output stable class averages. Images that cannot be accounted for by the current classes are set aside.

The determined class averages and their associated images, called “accounted for”, are returned as output.

The remaining, “unaccounted for” images, are forwarded to the next round of **ISAC** clustering (called generation).

The program will terminate once no further stable class averages can be produced.

Finally, the particle members of stable output classes are returned as “Processed”, while any particles that could not be accounted for are returned as “NotProcessed”.

|||ITEMIZEARROWEND|||

In the main window of the |||SPHIRE||| |||GUI||| click button **ISAC2** on the left and then the ***ISAC2 - 2D Clustering*** button in the middle.

|||FIGUREGUI|||06\_gui\_cluster.png|||FIGUREGUIEND|||

Fill out the following input fields:

|||ITEMIZEGUI|||

|||ITEM||| **Input image stack:** bdb:Particles\#stack

|||ITEMNOTE|||

Click the ***Select** **BDB image stack*** button, and use the file browser to select the virtual stack created in the previous step (containing all single particles in the project).

|||ITEMNOTEEND|||

|||ITEMTIP|||

In principle, you can also directly load any type of single particle dataset that was created by a different program, as long as it was converted to **EMAN2**’s |||BDB||| or |||HDF||| file format (preferably |||BDB|||), and if the |||CTF||| information is stored in the header of particles in the expected format.

In particular, **RELION** data files (stacks and metainformation stored in *.star* files) can be directly converted using the **sp\_relion2sphire.py** utility).

To access this tool, in the main window of the |||SPHIRE||| |||GUI||| first click the pictogram **UTILITIES** on the left and then the ***RELION to SPHIRE conversion*** button in the middle. Detailed instructions are provided in the **Import a star file** page of the |||WIKI|||. |||URL|||http: //sphire.mpg.de/wiki/doku.php?id=howto:relion2sphire |||URLEND|||.

|||ITEMTIPEND|||

|||ITEM||| **Output directory:** Class2D

|||ITEM||| **Particle radius \[Pixels\]:** 145

|||ITEM||| **Images per class:** 100

|||ITEMNOTE|||

Our dataset contains about 12628 particles, thus by setting this parameter to 100, the expected number of 2D averages will be about

|||EQUATION|||

\\text{Number of classes}=\\frac{\\text{Total Number of Particles}}{\\text{particles per class}}=\\frac{12628}{100}\\approx126\\,.

|||EQUATIONEND|||

|||ITEMNOTEEND|||

|||ITEMTIP|||

Proper setting of the desired number of particles per class requires some experience and testing multiple **ISAC2** runs with different settings might be necessary in order to obtain optimal results.

100 to 200 particles per class is a good starting point for |||CRYO-EM||| datasets of high quality containing about 50.000 to 100.000 particles. For early exploratory analysis of very large, autopicked datasets you may want to consider using a larger number (i.e., 500 to 2000) of particles per class.

Moreover, depending on the appearance of the resulting class averages, you may need to adjust this value accordingly.

For example, if the resulting averages are excessively noisy, it often helps to repeat **ISAC2** run using a larger number of particles per class.

However, this is always at the expense of the amount of detail in the final averages:

The larger the number of members per averages, the worse the amount of discernible details in the resulting averages.

Note that the computational time of **ISAC2** is a steeply raising function of the number of class averages and to obtain high-quality homogeneous (i.e., with possibly few members) class averages, significant processing resources have to be invested.

It should be also emphasized that in the next step of *ab initio* structure determination (**VIPER**) you will need at least 100 to 150 high quality class averages to produce a reliable 3D model.

|||ITEMTIPEND|||

|||ITEMTIP|||

The final number of particles per class and the number of classes are determined by the algorithm itself based on its ability to align them consistently and thus form stable class averages.

The number does not depend on the number of input images but rather on their quality and heterogeneity of the set, i.e., the number of distinct views, different conformational states, etc.

Setting the number too high (typically more than a few hundred) may result in heterogeneous (a.k.a. "fake") class averages and/or the rejection of rare views by the program.

|||ITEMTIPEND|||

|||ITEMTIP|||

Use 50 to 150 members per class for negative stain datasets of 5000 to 15000 particles.

|||ITEMTIPEND|||

|||ITEM||| **CTF phase flipping:** YES

|||ITEMTIP|||

Deactivate this flag for negative stain data.

|||ITEMTIPEND|||

|||ITEM||| **Phase Plate Data:** NO

|||ITEMNOTE|||

Activate this option if you process Phase Plate Data.

|||ITEMNOTEEND|||

Listed below are advanced options, please do not change the default values unless you understand their meaning well.

|||ITEMIZEGUIEND|||

Advanced parameters:

|||ITEMIZEGUI|||

|||ITEM||| **Pixel error threshold \[Pixels\]:** 0.7

|||ITEMNOTE|||

**ISAC2** evaluates quality of class averages by performing multiple reference-free *ab initio* alignments of images within a class.

Orientation parameters of individual images determined in these independent runs are compared, and their dispersion is reported as the **pixel error** of a given class (or image).

Class averages whose **pixel errors** exceed the pre-set threshold are discarded and their image members are set aside for processing in the subsequent generation.

**The pixel error** **threshold** is thus one of the most important **ISAC2** parameters.

|||ITEMNOTEEND|||

|||ITEMTIP|||

For **ISAC2** runs with large datasets of excellent quality and low number of particles per class (e.g. 100), one should use the rather conservative default value for this threshold (0.7).

With increased number of particles per class or if you expect a high degree of flexibility in your particle, you should set a higher threshold value (for example 1.7). Otherwise, **ISAC2** might discard too many particles.

|||ITEMTIPEND|||

|||ITEM|||

**Target** **particle radius \[Pixels\]:** 29

|||ITEMNOTE|||

Leave the default value.

|||ITEMNOTEEND|||

|||ITEM||| **Target particle image size \[Pixels\]:** 76

|||ITEMNOTE|||

Leave the default value.

|||ITEMNOTEEND|||

|||ITEMNOTE|||

To speed up the process, the particles of the input dataset are resized to match the user-provided particle radius and image size.

The default and thoroughly tested values are |||SI|||29 pixels|||SIEND||| radius and the box size |||SI|||76 pixels|||SIEND|||, respectively.

Thus, the resulting class averages will have a new (usually larger) pixel size and most probably high-resolution features (such as secondary structure elements) will not be visible.

The higher-resolution information is not lost though and will be restored later in the subsequent Beautifier step. The conversion formula is:

|||EQUATION|||

\\text{Target particle radius} = \\frac{\\text{Target particle image size} |||TIMES||| \\text{Original particle radius}}{\\text{Original particle image size}}

|||EQUATIONEND|||

|||ITEMNOTEEND|||

|||ITEMNOTE|||

Computational time will increase exponentially with increased target particle image size.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Specify the number of processors (48 in our case) and submit the job to the queuing system of the cluster using an appropriate submission script by clicking the ***Run command*** button.

Monitor progress of the job through the standard output.

On our cluster, this job running on 48 processors finished after about |||SI|||21 minutes|||SIEND|||.

|||NEWLINE|||

However, if you do not have enough time to wait for the results, copy our precalculated results to your **project directory**.

|||TERMINAL|||

cp -Rp SphireDemoResults/Class2D ./

|||TERMINALEND|||

Once the job has finished, the Class2D folder will contain the following folders and files:

|||ITEMIZEDASH|||

|||ITEM||| **2dalignment folder:** Contains the results of the (optional) reference-free prealignment.

|||ITEMNOTE|||

Display the total-average of your dataset after the pre-alignment\\\\ (**Class2D/2dalignment/aqfinal.hdf**) using the ***Display Data*** utility.

|||ITEMNOTEEND|||

|||FIGURESMALL|||06\_total\_average.png|||FIGURESMALLEND|||

|||ITEMTIP|||

Confirm that the 2D total-average is properly centered and that the circular 2D mask covers the entire particle.

If this is not the case, increase the particle radius (project-wide parameter) and rerun **ISAC2**.

|||ITEMTIPEND|||

|||ITEM||| **class\_averages.hdf:** Contains the final stable class averages.

|||ITEMTIP|||

If the file is not produced or contains only few class averages, it means that given the quality of the data the value of **Pixel error threshold \[pixels\]** parameter was set too low and thus too many class averages were eliminated during the stability tests.

In this case, you can try to increase the value of **Pixel error threshold \[pixels\]** and run **ISAC2** again.

If this does not help either, consider recording a dataset with better contrast and/or improve the quality of picking.

In most cases it is not possible to determine a reliable structure from a dataset that does not yield good (i.e., with distinct features) 2D class averages.

In the case of a dataset containing many images of contamination (e.g. if you set a rather low confidence threshold during autopicking with **crYOLO**), a second **ISAC2** run might be necessary to obtain the best results.

|||ITEMTIPEND|||

|||ITEM||| **processed\_images.txt:** Contains the particle IDs of the members of the stable class averages.

|||ITEMNOTE|||

At the terminal, type:

|||TERMINAL|||

wc –l Class2D/processed\_images.txt

|||TERMINALEND|||

This command will count the number of lines in the specified file.

This corresponds to the total number of particles assigned to stable class averages.

For the precalculated results this file has 11516 entries.

|||ITEMNOTEEND|||

|||ITEM||| **not\_processed\_images.txt:** Contains the particle IDs of the particles not assigned to stable class averages.

|||ITEMNOTE|||

At the terminal, type:

|||TERMINAL|||

***wc –l Class2D/not\_processed\_images.txt***

|||TERMINALEND|||

The printed number corresponds to the total number of particles not assigned to class averages.

For the precalculated results **ISAC2** discarded 1142 “bad” particles.

|||ITEMNOTEEND|||

|||ITEMIZEDASHEND|||

|||NOTE|||

If the **ISAC2** run completed at least one main iteration but crashed afterwards for some reason, it is possible to restart calculations using the “Continue mode”.

Open the **ISAC2 - 2D Clustering** page of the |||SPHIRE||| |||GUI||| and enter the exact same settings you used for the unfinished **ISAC2** run.

Then first click the “advanced settings” button, set the “Restart Run” parameter at the bottom to 0 and then click the ***Run command*** button to submit the job.

The program will identify the last fully completed main iteration and continue from there.

|||NOTEEND|||

Display the final stable class averages (**Class2D/class\_averages.hdf**) using the ***Display Data*** utility.

|||FIGUREGUI|||06\_isac\_classes.png|||FIGUREGUIEND|||

The high quality of this dataset is reflected by the impressive quality of the 2D class averages.

As mentioned above, in order to speed up the process, the particles of the input dataset are resized to a large pixel size and high-resolution features are not visible.

However, the stable 2D class averages will be further processed in the subsequent **Beautifier** step and high-resolution information will be restored.

|||NEWLINE|||

To facilitate a better comparison between the stable class averages, **ISAC2** realigns them relative to each other and orders them based on pair-wise similarity.

The result is stored in the file: **Class2D/ordered\_class\_averages.hdf**

|||NEWLINE|||

Display the ordered and aligned final stable class averages \\\\(**Class2D/ordered\_class\_averages.hdf**) using the **Display Data** utility.

|||FIGUREGUI|||06\_isac\_classes\_ordered.png|||FIGUREGUIEND|||

|||ISSUE|||{\!Known issue in the release}

We optimized the parallelization of **ISAC2** and the current **ISAC2** version can now handle large datasets.

On our cluster with |||SI|||128 giga byte|||SIEND||| of RAM and 24 cores per node, we managed to successfully process datasets with up to 750000 particles.

However, larger datasets or large datasets of lower quality might still fail due to insufficient memory.

The suggested workaround is to split the data into subsets: Run **ISAC2** for each subset separately, as described above, and then combine the results.

For example, to split a dataset in 4 subsets type at the terminal (it is one long line command):

|||NEWLINE|||

|||TERMINAL|||

n=4; for i in $(seq 0 $((n-1))); do e2bdb.py bdb:Particles\#stack\\\\ --makevstack=bdb:Particles\#stack\_$\\{i\\} --step=$\\{i\\},$\\{n\\}; done

|||TERMINALEND|||

|||NEWLINE|||

The stack bdb:Particles\#stack\_0 contains every fourth particle of the original stack starting from index 0, the stack bdb:Particles\#stack\_1 contains now every fourth particle of the original stack starting from index 1 and so on.

|||NEWLINE|||

This command creates 4 virtual particle stacks. You can easily change the number of substacks by changing the 4 in the beginning of the command to the desired value.

|||NEWLINE|||

To combine the clean stacks obtained from 4 runs of **ISAC2** into a single virtual stack, use the following before proceeding to the next step \\nameref{VIPER} (it is one long line command):

|||NEWLINE|||

|||TERMINAL|||

e2bdb.py bdb:Particles\#isac\_substack\_1 bdb:Particles\#isac\_substack\_2\\\\ bdb:Particles\#isac\_substack\_3 bdb:Particles\#isac\_substack\_4\\\\ --makevstack=bdb:Particles\#stack\_all

|||TERMINALEND|||

|||ISSUEEND|||

If you do not have enough time to perform the described steps, copy our precalculated **ISAC2** results and the resulting clean dataset to the **project directory**.

|||TERMINAL|||

cp -Rp SphireDemoResults/Class2D ./\\\\  
cp -Rp SphireDemoResults/Particles ./

|||TERMINALEND|||

Most class averages show the typical pineapple-like shape of the side-view of the prepore state of the TcdA1 toxin \\parencite{Gatsogiannis:2013}.

However, several class averages (Nr. 0-5 in the precalculated results) differ considerably;

they show an umbrella-like shape and correspond to the pore state of the complex \\parencite{Gatsogiannis:2013, Gatsogiannis:2016}.

Thus, the present dataset includes a mixture of two populations corresponding to two different conformational states of the same complex in a ratio of approximately 1:20.

|||NEWLINE|||

We will now delete these class averages using the ***Display Data*** Utility.

For this purpose, in the main window of the |||SPHIRE||| |||GUI|||, click the **Display Data** button under **UTILITIES** and load the file **Class2D/ordered\_class\_averages.hdf**.

|||TIP|||

Usually, at this step we only delete “junk” class averages (e.g. blurry class averages, ice contamination, carbon edges etc.) and then let **RVIPER** identify and exclude outliers during the initial model generation procedure.

However, in this the case the structural differences are very obvious, and therefore we will delete these classes right away.

|||TIPEND|||

To delete “bad” class averages or outliers, press the mouse wheel button somewhere on the graphics window and activate the ***Del*** button |||REDNUM|||(1)|||REDNUMEND|||, in the pop-up window.

|||FIGUREGUI|||06\_isac\_del.png|||FIGUREGUIEND|||

Next, select the "bad" class averages by clicking on the respective images |||REDNUM|||(2)|||REDNUMEND||| and click the ***Save*** button |||REDNUM|||(3)|||REDNUMEND||| to save the remaining images under a new name: **Class2D/best.hdf**.

|||TIP|||

In the pop-up graphics window, you can also click the ***Values*** button and select the ***n\_objects*** parameter in order to display the number of images for each class average.

|||TIPEND|||

These class averages (**Class2D/best.hdf**) will be used to generate an initial 3D model with **RVIPER**.

|||SECTION|||Beautifier|||SECTIONEND|||

In order to speed up calculations, we resized the particles of the input dataset during **ISAC2** to a smaller box and a larger pixel size.

Most importantly, we did not apply full |||CTF||| correction;

instead, images were only phase-flipped.

Therefore, in most cases, because these operations remove high-resolution information from the data, possible fine details (such as secondary structure elements) will not be visible in the **ISAC2** 2D class averages.

|||NEWLINE|||

The **Beautifier** tool extracts the members of each **ISAC2** class average from the original, full-size dataset, performs local 2D refinement and applies full |||CTF||| correction. Afterwards, the full-size class averages are aligned and ordered by pair-wise similarity.

It is also possible to request a low-pass filtration to suppress high-resolution noise.

Thus, **Beautifier** tool provides full-size aligned averages computed at fully attained resolution.

|||TIP|||

High-resolution datasets will in most cases yield “beautified” class averages with distinct high-resolution features.

Thus, the results of the current processing step provide a good checkpoint to verify that the project has the potential for high-resolution 3D structure determination.

|||TIPEND|||

|||TIP|||

It is not necessary to use the Beautifier tool for negative stain data.

|||TIPEND|||

In the main window of the |||SPHIRE||| |||GUI|||, click the ***ISAC2*** button on the left and then the ***Beautifier*** button in the middle.

|||FIGUREGUI|||06\_gui\_beautifier.png|||FIGUREGUIEND|||

Fill out the following input fields of the |||GUI|||:

|||ITEMIZEGUI|||

|||ITEM||| **Original image stack:** bdb:Particles\#stack

|||ITEMNOTE|||

Click the ***Select BDB image stack*** button, and use the file browser to select the virtual stack containing all particles in the **Particles** folder.

You **have to** select the stack used as input to perform the 2D Classification with **ISAC2**.

|||ITEMNOTEEND|||

|||ITEM||| **ISAC2 run directory:** Class2D

|||ITEMNOTE|||

Click the ***Select directory*** button, and use the file browser to select the **ISAC2** output directory.

|||ITEMNOTEEND|||

|||ITEM||| **Output directory:** Beaut

|||ITEM||| **Particle radius \[Pixels\]:** 145

|||ITEMNOTE|||

You must use the original particle radius (145) and **not** the target particle radius used during **ISAC2** (29).

|||ITEMNOTEEND|||

|||ITEM||| **CTF correction:** YES

|||ITEMNOTE|||

Activate the checkbox to apply full |||CTF||| correction.

Do not activate if you are processing negative stain data.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Advanced parameters:

|||ITEMIZEGUI|||

|||ITEM||| **Local alignment:** YES

|||ITEMNOTE|||

Activate the checkbox to perform a local alignment of the **ISAC2** averages.

The “beautified” class averages will improve, but also the computational time will increase as well.

|||ITEMNOTEEND|||

|||ITEM||| **Low-pass filter cutoff resolution \[1/Pixel\]:** 0.285

|||ITEMNOTE|||

Here you can specify, a cutoff for the low-pass filter to be applied (in absolute frequency units \[1/Pixel\]). You can also use our calculator to convert resolution in |||UNIT|||angstrom|||UNITEND||| to absolute frequency.

|||FIGUREMEDIUM|||06\_gui\_calculator.png|||FIGUREMEDIUMEND|||

To do so, click the ***Use resolution\[A\]*** button;

in the pop-up window set the resolution to |||SI|||6 angstrom|||SIEND|||, and then click the ***Convert units*** button.

A resolution of |||SI|||6 angstrom|||SIEND||| corresponds to an absolute frequency of 0.19 with a given pixel size of |||SI|||1.14 angstrom|||SIEND|||.

|||NEWLINE|||

The conversion formula is:

|||EQUATION|||

\\text{Absolute frequency} = \\frac{\\text{Resolution}}{\\text{pixel size}}

|||EQUATIONEND|||

Now click the ***Apply*** button to set this value in the low-pass filter frequency input field.

|||ITEMNOTEEND|||

|||ITEMNOTE|||

According to the above setting, the “beautified” class averages will be low pass filtered to |||SI|||6 angstrom|||SIEND||| \[Absolute frequency 0.19\]. We prefer to apply this filter, since the class averages contain only a few members (100 members/group).

If you do not wish to low-pass filter the averages, use the default value of -1 instead (low-pass filter will not be applied).

Setting this parameter to 0 will low-pass filter to the resolution automatically determined from the **ISAC2** averages **before** the local refinement; setting it to -2, the program will low-pass filter to the resolution automatically determined from the **ISAC2** averages **after** the local refinement.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Specify the number of processors (for this job, we used 48) and submit the job to the queuing system of the cluster using an appropriate submission script by clicking the ***Run command*** button.

On our cluster this job took about |||SI|||7 minutes|||SIEND||| using 48 processors.

Display the final stable, resized, refined, power-spectrum adjusted and |||CTF|||-corrected and ordered class averages (**Beaut/ordered\_class\_averages.hdf**) using the **Display Data** utility.

|||FIGUREGUI|||06\_beaut\_ordered.png|||FIGUREGUIEND|||

Click the **mouse wheel button** while pointing somewhere on the graphics window and adjust the **brightness** and the **contrast** at the **e2display.py** pop-up window.

The high quality of this dataset is reflected again in the high level of detail of the beautified 2D class averages.

Delete the class averages of the pore state of the complex, as described in the previous section, and store the remaining images in a new file named “**Beaut/ best.hdf**”.

|||TIP|||

Direct visualization of secondary structure elements in 2D class averages requires a sufficiently large dataset and a class-size of 1000 to 2000 members.

|||TIPEND|||

Beautified class averages can also be used to calculate an initial model using **RVIPER**.

In several cases we used them to obtain sub-nanometer structures, and thus better initial models.

However, running time of **RVIPER** increases significantly with the box size.

Therefore, we generally recommend using the downscaled **ISAC2** class averages as input for **RVIPER** instead.

|||SECTION|||ISAC2 Stack Subset|||SECTIONEND|||

The initial model that we will calculate in the next step (**RVIPER**) will be refined against the particle members of the selected class averages (the “clean” stack). This will be done in our **MERIDIEN** 3D structure refinement.

|||NEWLINE|||

Now, we will create a virtual “clean” particle stack that will contain only the members of the selected class averages (**Beaut/best.hdf**).

|||NEWLINE|||

It should be emphasized that the **Beautifier** tool performs a local 2D refinement of the particle members of the beautified, full resolution class averages and centering is in general improved.

The resulting orientation parameters can be passed later to the 3D **MERIDIEN** refinement helping to accomplish higher resolution of the final map at a shorter time of calculations.

Therefore, we store in the header of the particles of the “clean” stack the 2D alignment parameters.

In the main window of the |||SPHIRE||| |||GUI|||, click the button ***ISAC2*** on the left and then the ***ISAC2 Stack Subset*** button in the middle.

|||FIGUREGUI|||06\_gui\_isac\_substack.png|||FIGUREGUIEND|||

Next, fill out the following input fields:

|||ITEMIZEGUI|||

|||ITEM||| **Input BDB image stack:** bdb:Particles\#stack

|||ITEMNOTE|||

Click the ***Select BDB image stack*** button, and use the file browser to select in the **Particles** folder the virtual stack that contains all particles in the **Particles** folder.

|||ITEMNOTEEND|||

|||ITEM||| **ISAC or Beautifier run output directory:** Beaut

|||ITEMNOTE|||

Click the ***Select directory*** button, and use the file browser to select the output directory of the **Beautifier** run.

From this directory the program will import the 2D alignment parameters provided by the **Beautifier** local refinement and store them to the header of the extracted particles.

|||ITEMNOTEEND|||

|||ITEMTIP|||

If you skipped the **Beautifier** step, you should select the **ISAC2** output directory (**Class2D**) instead.

In this case the 2D parameters stored in the header of the resulting “clean” stack will be imported from the **ISAC2** 2D alignment parameters.

Keep in mind that since **ISAC2** performs the alignment and clustering on downscaled images, the x-, y-shifts will be less precise, and the 3D refinement will not start from the best possible centering parameters and might need more iterations to converge.

|||ITEMTIPEND|||

|||ITEM||| **Output directory:** Substack

|||ITEM||| **ISAC2 or Beautifier class averages path:** Beaut/best.hdf

|||ITEMNOTE|||

Click the ***Select HDF image*** button, and use the file browser to select the file that contains the selected class averages.

|||ITEMNOTEEND|||

|||ITEM||| **Stack subset basename:** isac\_substack

|||ITEMNOTE|||

Particles that are members of selected class averages will be stored in a virtual |||BDB||| file named **isac\_substack** in the specified output directory (**bdb:Substack\#isac\_substack**).

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Click the ***Run command*** button and check the output of the job.

|||NEWLINE|||

At the terminal, type:

|||TERMINAL|||

tail -f name\_of\_sp\_pipe\_logfile

|||TERMINALEND|||

|||STDOUT|||

Found 11516 entries in Beaut/ali2d\_local\_params.txt

|||NEWLINE|||

Detected 110 ISAC class averages in Beaut/best.hdf

|||NEWLINE|||

Extracted 10949 ISAC class members from Beaut/best.hdf

|||STDOUTEND|||

The “clean” stack contains 10949 particles. In the case of this high-quality dataset, we eliminated about |||SI|||16 percent|||SIEND||| of particles.

|||TIP|||

For most of our datasets the number of eliminated particles is usually much higher (|||SI|||20 percent|||SIEND||| to |||SI|||30 percent|||SIEND|||).

Sometimes the number of accounted for particles does not even reach |||SI|||50 percent|||SIEND|||, but it is nevertheless preferable to work with a smaller but cleaner dataset.

|||TIPEND|||

|||TIP|||

If the dataset contains populations of particles whose shape differ significantly (e.g. different oligomers or proteins) and which are easily recognizable, we recommend storing the respective class averages and their members in different files and performing the subsequent steps of structure determination for each subset independently.

|||TIPEND|||

|||CHAPTERORANGE|||VIPER|||CHAPTERVIPER|||

|||SECTION|||Initial 3D Model - RVIPER|||SECTIONEND|||

The **RVIPER** program is designed to determine a reproducible and validated initial model at intermediate resolution using a small subset of class averages produced by **ISAC2**.

|||NEWLINE|||

First, check the number of your selected **ISAC2** class averages.

|||TERMINAL|||

e2iminfo.py Class2D/best.hdf

|||TERMINALEND|||

In general, about 150 high quality class averages are sufficient to obtain a validated initial structure in a reasonable amount of time.

Although **RVIPER** would likely provide better results with more than 150 averages, computational time would increase significantly as well and in most cases there would be no significant improvement of the resulting model.

|||NEWLINE|||

After running **ISAC2**, we deleted the averages of the second population.

The output file **best.hdf**, contains only 110 class averages (the exact number of class averages can slightly differ due to the internal randomization used during the initialization of the **ISAC2** clustering process).

However, the test complex has C5 symmetry and therefore the available number of class averages should be sufficient to calculate a reliable 3D model with **RVIPER**.

|||TIP|||

In order to run **RVIPER** successfully for cryo data it is necessary to have at least 60 to 80 high quality averages with about 100 to 200 members each (for negative stain about 100 members).

Be sure that the input class averages include as many orientations of the particle, as possible.

It will not be possible to calculate a structure from images dominated by one (or a few) preferred orientation(s).

If class averages contain only few members or have a low signal to noise ratio, you might need to use more than 150 class averages for **RVIPER**, particularly in the case of asymmetric complexes.

|||TIPEND|||

In the main window of the |||SPHIRE||| |||GUI|||, click button **VIPER** on the left and then the Initial ***Initial3D Model - RVIPER*** button in the middle.

|||FIGUREGUI|||07\_gui\_rviper.png|||FIGUREGUIEND|||

Fill out the following input fields:

|||ITEMIZEGUI|||

|||ITEM||| **Input images stack:** Class2D/best.hdf

|||ITEM||| **Output directory:** Initial3D

|||ITEM||| **Target particle radius \[Pixels\]:** 29

|||ITEMIMPORTANT|||

Use the same target particle radius as the one used for **ISAC2**.

|||ITEMIMPORTANTEND|||

|||ITEM||| **Point-group symmetry:** C5

|||ITEMTIP|||

Use C1 if the symmetry of the complex is not known.

|||ITEMTIPEND|||

|||ITEMIZEGUIEND|||

Advanced parameters:

|||ITEMIZEGUI|||

|||ITEM||| **Restarting iteration:** 0

|||ITEMNOTE|||

If your **RVIPER** run crashed for some reason, set this parameter to 0 and resubmit the job.

The program will then identify the latest fully completed iteration and continue from there.

|||ITEMNOTEEND|||

|||ITEM||| **Eliminate disconnected regions:** 1400,1.14

|||ITEMNOTE|||

Enter the approximate molecular weight of the complex (|||UNIT|||kilo dalton|||UNITEND|||) and the pixel size (|||UNIT|||angstrom|||UNITEND|||), separated by a comma.

Based on these values the program will compute, after each iteration, the threshold at which the candidate structure occupies the expected volume (in voxels).

Any disconnected pieces that will appear at this threshold will be eliminated and the corrected 3D structure will be used as reference for the next iteration.

The intention is to force the program to favour candidate structures that have "structural integrity", as reasonably expected for physically plausible macromolecular complexes.

|||ITEMNOTEEND|||

|||ITEMNOTE|||

If the molecular weight is underestimated or there is strong complex flexibility the program may eliminate valid regions of the structure, a problem particularly common with negative stain data;

In this case, try to increase the molecular weight value and restart the program.

If in doubt, one can also perform two runs of **RVIPER**: one with elimination of disconnected regions, one without and afterwards compare the results.

|||ITEMNOTEEND|||

|||ITEMTIP|||

To suppress the above functionality, enter "none" into the input field.

|||ITEMTIPEND|||

|||ITEMIZEGUIEND|||

Specify the number of processors (for this job we used 48) and submit the job to the queuing system of the cluster using the appropriate submission script and by clicking the ***Run command*** button.

Monitor the progress of the job through the standard output. On our cluster this job required about |||SI|||27 minutes|||SIEND||| to complete.

|||NOTE|||

Note, that the number of processors needs to be a multiple of the advanced settings option **GA population size** (default 4).

|||NOTEEND|||

|||ISSUE|||{\!Known issue\!}

The program might crash if the number of processors exceeds the number of class averages.

|||ISSUEEND|||

**RVIPER** (**R**eproducible **VIPER**) performs multiple **VIPER** runs (*ab initio* 3D structure determination using a small set of ISAC2 class averages) and thus calculates multiple initial models.

It performs a reproducibility test, removes unstable projections and produces a single validated initial model.

|||NEWLINE|||

After the program finished, output **main|||REDNUM|||ITERNR|||REDNUMEND|||** folders are placed in the **Initial3D** output.

The number of **main|||REDNUM|||ITERNR|||REDNUMEND|||** folders corresponds to the number of **RVIPER** iterations.

Folders named **run|||REDNUM|||ITERNR|||REDNUMEND|||** within each main folder contain the results of each independent **VIPER** run.

In our case there is only one such folder: **main001**.

The final reproducible structure is **Initial3D /average\_volume\_001.hdf**.

|||TIP|||

If the internal stability criterion is not met after 10 independent **VIPER** runs, the program will stop (it will not continue to the final iteration) and no average structure will be created.

However, we still recommend careful examination of the output structures from all independent runs (i.e., **volf.hdf** and **refvol2.hdf** in the subdirectories **main001/run|||REDNUM|||ITERNR|||REDNUMEND|||**) as some of them might fit the input data sufficiently well and thus might serve as suitable initial models in the subsequent 3D **MERIDIEN** structure refinements.

Nevertheless, it should be emphasized that these structures are not validated and therefore their quality has to be assessed visually. In particular their structural integrity, i.e., presence of "moons" (significant large densities) floating around the main body of the structure can indicate problems.

|||TIPEND|||

Keep in mind that one cannot determine the hand of a 3D structure based on the set of its 2D projections alone.

Therefore, **RVIPER** might have produced an enantiomer (mirror structure).

There is no way to establish correct handedness of low-resolution models short of performing tilt experiments.

In our case the hand of the test structure is known and therefore the handedness of the map obtained from the current **RVIPER** run can be set correctly already at this point.

For this purpose, display the **RVIPER** map using the molecular graphics program **UCSF Chimera** \\parencite{Pettersen:2004kh}.

|||FIGUREGUI|||07\_hand.png|||FIGUREGUIEND|||

Compare the appearance of the obtained **RVIPER** maps with the images above and check if your map has the correct handedness. If not, it will be necessary to mirror the structure about the x-y plane (that is along the z-axis). This can be performed in the subsequent **Volume adjustment** step.

|||TIP|||

In case neither the handedness of the complex is known nor a homologous structure is available, you should either perform a tilt experiment or proceed with 3D refinement using the obtained **RVIPER** model.

Once sufficient resolution is reached, you can establish the correct hand based on the visual appearance of secondary structure elements.

|||TIPEND|||

|||SECTION|||Compare re-projections|||SECTIONEND|||

During a RVIPER run, orientation parameters for each 2D class average are determined, which are finally used to compute the initial 3D model. The **Compare Re-projections** tool can now be used to produce side-by-side comparisons of the 2D class averages with the respective projections of the initial 3D model. This provides a helpful tool to validate the quality of the 2D class averages, the assigned orientation parameters and the robustness of the initial 3D model.

Click the **Compare Re-projections** button in the middle of the |||SPHIRE||| |||GUI|||.

|||FIGUREGUI|||08\_gui\_reproj.png|||FIGUREGUIEND|||

Fill out the following fields:

|||ITEMIZEGUI|||

|||ITEM||| **Input images stack:** Class2D/best.hdf

|||ITEMNOTE|||

Click the ***Select HDF image*** button, and use the file browser to select in the **Class2D** folder the stack containing the selected class averages of the prepore state (**best.hdf**), which were also used as input for RVIPER.

|||ITEMNOTEEND|||

|||ITEM||| **Input volume:** Initial3D/main001/run002/rotated\_volume.hdf

|||ITEMNOTE|||

Click the ***Select HDF volume*** button, and use the file browser to select an RVIPER volume

|||ITEMNOTEEND|||

|||ITEM||| **Output directory:** Compare2D

|||ITEM||| **Comparison method:** viper

|||ITEMTIP|||

If you skipped **RVIPER** and wish to perform the comparison with an available 3D volume, type here the option **projmatch** instead. The program will then perform projection matching to find the best match between the class averages and the 2D projections of the 3D volume, at a user-selected angular interval.

|||ITEMTIPEND|||

|||ITEM||| **VIPER – Projection parameter file:** Initial3D/main001/run002/rotated\_reduced\_params.txt

|||ITEMNOTE|||

Click the ***Select projection params*** button, and use the file browser to select the file containing the assigned projection parameters for the respective RVIPER run.

|||ITEMNOTEEND|||

|||ITEM||| **VIPER – Image selection file:** Initial3D/main001/index\_keep\_images.txt

|||ITEMNOTE|||

Click the ***Select image list*** button, and use the file browser to select the file containing the list of class averages which were considered stable during initial model generation.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

and click the **Run Command** button.

This process is usually finished after few seconds.

Display the comparison file (**Compare2D/comp-proj-reproj.hdf**) using the ***Display Data*** utility. Each class average will be shown next to the respective re-projection, and both images should show an excellent agreement.

|||FIGUREGUI|||08\_reproj.png|||FIGUREGUIEND|||

At this point we also strongly recommend to compare at this point the **RVIPER** structure with the available X-ray crystallographic structure of TcdA1 (|||SI|||3.9 angstrom|||SIEND|||, |||PDB|||-ID: *1VW1* \\parencite{Meusch:2014jy}). Load the volume and the |||PDB||| file in **UCSF Chimera**, set the voxel size of the volume to |||SI|||5.7 angstrom|||SIEND||| (see \\nameref{Volume Adjustment} section below for details) and fit the atomic model into the density map using **Fit in Map**.

They should show an excellent agreement, even though at the current resolution only the overall envelope of the |||ELM||| model is reliable.

|||FIGUREGUI|||08\_map\_xray.png|||FIGUREGUIEND|||

|||NEWLINE|||

You can also create a *.bild* file with the **Angular Distribution** utility to assess the angular distribution of the class averages used during the **VIPER** 3D reconstruction, as described on our |||SPHIRE||| |||WIKI||| page.

The file can also be displayed in **UCSF** **Chimera**.

|||TIP|||

Alternative to the procedure described above, instead of using the downscaled **ISAC2** class averages as input for **RVIPER**, one can also calculate an initial 3D model directly from the beautified class averages with the original pixel size.

However, the computational time for **RVIPER** on averages of original image size increases by the square of their size.

Depending on the quality of the averages, the advantage of running **RVIPER** on original image size is that you might be able to obtain directly from beautified class averages initial models at |||SI|||6 angstrom|||SIEND||| to |||SI|||9 angstrom|||SIEND|||.

For this approach however, you will have to set the **Low-pass filter frequency \[1/Pixels\]** (***Advanced*** option) (filter to be applied to the **RVIPER** structures) to an appropriate value before submitting the job.

|||TIPEND|||

|||TIP|||

If an X-ray structure of a homologous complex is available and there is a high- degree of similarity expected, one can omit the *ab initio* structure determination with RVIPER, and use the available atomic coordinates instead. To do so, we use the PDB File Conversion utility (Alternatives) to convert the atomic model (typically downloaded from the PDB data base) to a density map.

|||TIPEND|||

If you do not have enough time to perform these steps, you can also copy our precalculated results to the **project directory**.

|||TERMINAL|||

cp -Rp SphireDemoResults/Initial3D ./

|||TERMINALEND|||

|||SECTION|||Volume Adjustment|||SECTIONEND|||

The particles of the dataset were resized during **ISAC2** (in this case from a radius of |||SI|||145 pixels|||SIEND||| and box size of |||SI|||352 pixels|||SIEND||| to a radius of |||SI|||29 pixels|||SIEND||| and box size of |||SI|||76 pixels|||SIEND|||).

Therefore, the **ISAC2** averages and the **VIPER** 3D model have now an increased pixel size of |||SI|||5.7 angstrom|||SIEND|||.

In order to use this model as a reference structure for the 3D refinement of the original dataset, we have to resize and window the **VIPER** model in order to match the dimensions and the pixel size of the original particle stack. In addition, we will mask the reference volume automatically in order to remove background noise and if necessary, invert its handedness.

To check the shrink ratio used to downscale the images before **ISAC2** type:

|||TERMINAL|||

cat Class2D/README\_shrink\_ratio.txt

|||TERMINALEND|||

Now click the ***Volume Adjustment*** button in the middle of the |||SPHIRE||| |||GUI|||.

|||FIGUREGUI|||07\_gui\_size.png|||FIGUREGUIEND|||

Fill out the following fields:

|||ITEMIZEGUI|||

|||ITEM|||**Input Volume Path:** Initial3D/average\_volume\_001.hdf or Initial3D/average\_volume\_001\_flip.hdf

|||ITEM||| **Output Directory:** VolumeAdjust

|||ITEM||| **Output pixel size:** 1.14

|||ITEM||| **Use molecular mass:** Yes

|||ITEM||| **Molecular mass \[kDa\]:** 1400

|||ITEMNOTE|||

The program will eliminate “moons” (background noise densities) based on the molecular weight of the protein. It will automatically determine a threshold and eliminate densities not connected to the main volume.

|||ITEMNOTEEND|||

|||ITEM||| **Resample ratio:** Class2D

|||ITEMNOTE|||

Click the ***Select directory*** button, and use the file browser to select the ISAC directory (**Class2D**). The program will automatically extract the resampling ratio from the **README\_shrink\_ratio.txt** located in the **Class2D** folder and restore the original pixel size and dimensions of the RVIPER model accordingly.

|||ITEMNOTEEND|||

|||ITEM||| **Invert Handedness:** YES or NO?

|||ITEMNOTE|||

If your RVIPER volume shows the wrong hand, activate **the Invert Handedness** option.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Click the **Run Command** button.

This step is finished in few seconds.

Display the resulting volume (Volume\_Adjust/vol3d\_ref\_moon\_eliminated.hdf) using **UCSF Chimera**, and verify it shows all expected structural features.

|||TIP|||

If the molecular weight is underestimated or there is strong flexibility in the complex, the program may eliminate valid regions of the structure (particularly common with negative stain data). In this case, try to increase the molecular weight value and restart the program.

Alternatively, instead of the automatic “moon” elimination, you can use an ad-hoc threshold value (**Use ad hoc density threshold**). To do so, first deactivate the **Use molecular mass** option. Determine an appropriate threshold for the volume (using **Volume Viewer in UCSF Chimera**) lower than you would normally use for displaying the structure, and fill the respective field. Noise artifacts can be visible but not connected to the molecule density.

|||TIPEND|||

|||SECTION|||Adaptive 3D Mask|||SECTIONEND|||

Now click the ***Masking*** button in the middle of the |||SPHIRE||| |||GUI|||.

|||FIGUREGUI|||08\_gui\_mask.png|||FIGUREGUIEND|||

Fill out the following fields:

|||ITEMIZEGUI|||

|||ITEM||| **Input image:** Volume Adjust/vol3d\_ref\_moon\_eliminated.hdf

|||ITEMNOTE|||

This is the **RVIPER** result after resizing and windowing to the original box/pixel size.

|||ITEMNOTEEND|||

|||ITEM||| **Output Directory:** 3DMask

|||ITEM||| **Use molecular Mass:** Yes

|||ITEM||| **Molecular Mass \[kDa\]:** 1400

|||ITEMNOTE|||

These are the parameters for the moon elimination tool (see the section above for instructions).

|||ITEMNOTEEND|||

|||ITEM||| **Number of dilations:** 3

|||ITEMNOTE|||

Numbers of cycles to extend this initial binarized structure; see the section below for instructions.

|||ITEMNOTEEND|||

|||ITEM||| **Soft-edge width \[Pixels\]:** 10

|||ITEMNOTE|||

This is the pixel-width for the transition area of the soft-edge mask. The default value is optimal for volumes with pixel size of roughly 1 Å. You will have to adjust this value if you are using a significantly different pixel size.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Click the ***Run command*** button.

This process is usually finished after few seconds.

Detailed description regarding the usage of this program is provided on our |||WIKI||| page.

|||ADVANCED|||{Masking}

Open the adjusted RVIPER volume (**Volume Adjust/vol3d\_ref\_moon\_eliminated.hdf** created in the previous step) and the 3D mask (3DMask/sp\_mask\_mask.hdf) with **UCSF Chimera**.

In order to compare both maps in **UCSF Chimera**, set their voxel sizes to |||SI|||1.14 angstrom|||SIEND||| (**Volume Viewer-\>Features-\>Coordinates-\>Voxel Size**: |||SI|||1.14 angstrom|||SIEND|||).

Check the size of the resulting mask relative to the initial map again using **UCSF Chimera** (we usually display the 3D mask transparent, as shown in the figure below).

|||FIGUREADV|||08\_ volume\_mask.png|||FIGUREADVEND|||

The generated mask should have the shape of the particle, but it should extend in all directions by a sufficient number of voxels (3 to 5) to prevent masking artifacts during 3D refinement.

The amount of extension is controlled by the number of dilations parameter (default set to 3; you may have to adjust this value).

The resulting mask should have sufficient clearance around to the map while excluding all satellite densities.

|||ADVANCEDEND|||

|||CHAPTERORANGE|||MERIDIEN|||CHAPTERMERIDIEN|||

In the previous steps we removed all “junk” images and produced a clean subset of particles which was aligned and clustered in a stable and reproducible manner using the powerful **ISAC2** approach.

Subsequently, from the validated **ISAC2** class averages we calculated a reproducible model.

These results give us confidence that we can now proceed with the structure refinement using the obtained model as a starting reference (3D Refinement; **MERIDIEN**).

|||NEWLINE|||

**MERIDIEN** employs a quasi-Maximum Likelihood approach (later referred to as |||ML|||).

Briefly, the set of 2D input images is randomly split into half-datasets and is refined quasi-independently in order to minimize noise bias and over-refinement.

During the projection-matching phase, the program estimates "probabilities" with which each particle image matches reference reprojections of the current approximation of the 3D structure.

Next, during the 3D reconstruction phase, the data is backprojected using all significant angular (and translation) directions with probabilities used as weights.

These two steps are then iterated.

Note both the maps and resolution curves (driver |||FSC|||s) generated during each iteration of the program serve only as internal approximations (i.e., the resolution reported after each iteration is usually underestimated).

Usable results are obtained after the refinement finishes. We use the ***PostRefiner*** utility to process the so-called unfiltered final half-volumes to produce the ultimate result, including the |||FSC||| curve.

|||NEWLINE|||

**MERIDIEN** provides the user with the following functionalities:

|||ENUMERATE|||

|||ITEM||| The standard use is to perform full 3D structure that starts from an initial, user-provided reference structure. By default the program will start from exhaustive searches without assuming any prior angular information. Any available alignment parameters (e.g. from **ISAC2**) will automatically be incorporated into the search in order to improve the convergence.

|||ITEM||| Local refinement mode is primarily meant to refine subsets obtained by 3D sorting.

This mode is described in detail in the subsequent sections.

It can also be used to locally refine datasets obtained by other software packages, as long as orientation parameters (both angles and translations) are stored in the input image headers in the expected format.

|||ITEM||| 3D reconstruction of full-size unfiltered maps using parameters obtained from a user-specified iteration of the **MERIDIEN** refinement.

|||ITEM||| Restart mode, which allows user to continue the refinement (either standard or local) should the program crash or run into a time limit (sometimes imposed by a computing cluster).

|||ENUMERATEEND|||

We will now use mode (1) and perform a high-resolution 3D refinement using the 3D reference volume and 3D mask produced in the previous steps.

|||TIP|||

In most cases **RVIPER** will deliver a highly reliable and detailed initial model.

Therefore, if the overall structure is already established, we recommend beginning the refinement immediately with a 3D mask.

Structure refinement that utilizes a reasonably tight mask proceeds faster and yields better (higher resolution) results.

In rare cases in which the initial model is of low quality or unreliable you should proceed with caution: first run a 3D refinement without using a 3D mask, validate the outcome and only then create a 3D mask and repeat the refinement.

|||TIPEND|||

|||SECTION|||3D Refinement|||SECTIONEND|||

3D refinement of the structure is done using the original individual particle images.

The standard default run (mode 1) starts from exhaustive searches using the resized **RVIPER** volume as an initial reference structure.

In the main window of the |||SPHIRE||| |||GUI||| first click the button ***MERIDIEN*** on the left and then the ***3D REFINEMENT*** button in the middle. Fill out the following input fields:

|||FIGUREGUI|||08\_gui\_refinement.png|||FIGUREGUIEND|||

|||ITEMIZEGUI|||

|||ITEM||| **Input image stack:** bdb:Substack\#isac\_substack

|||ITEMNOTE|||

Click the ***Select BDB image stack*** button, and use your file browser to select the unbinned clean subset of particles, containing only the members of the selected **ISAC2** class averages.

|||ITEMNOTEEND|||

|||ITEM||| **Output directory:** Refine3D

|||ITEM||| **Initial 3D reference:** Volume Adjust/vol3d\_ref\_moon\_eliminated.hdf

|||ITEMNOTE|||

Click the ***Select HDF volume*** button, and use your file browser to select the resized and windowed **RVIPER** structure.

|||ITEMNOTEEND|||

|||ITEMTIP|||

Here you can also directly load any type of 3D structure as an initial reference (i.e. any structure produced by another program, structures derived from X-ray crystallographic model, a simple sphere in case of high point group symmetry, etc.).

The file that contains the structure does not have to have any header information.

|||HDF||| is the primary |||SPHIRE||| format for 3D volumes, but *.mrc*, *.spi*, *bdb:*, *.img* and *.dm4* are also supported and can be directly loaded to the |||GUI||| by clicking the ***Select any volume*** button.  
Keep in mind that the box and voxel size of such an imported volume have to match the input dataset.

If this is not the case, the volume has to be resized using the **Volume Adjustment** utilities described above.

|||ITEMTIPEND|||

|||ITEM||| **Read shifts from header:** YES

|||ITEMNOTE|||

The 2D data should have already translation parameters stored in their headers, as they were computed during 2D alignment in **ISAC2** (and improved further by the **Beautifier** tool).

Refinements that use pre-centered particles converge faster and produce better results. Therefore, this flag is set to **YES** by default and the predetermined **ISAC2** shifts are imported from the header automatically.

If shifts are not available, set this flag to **NO**. In this case, the program will perform by default a reference-free 2D alignment in an attempt to roughly pre-center the particles. This significantly improves the performance by accelerating the convergence and improving the final resolution.

If shifts are not available, but your particles are pre-centered (for example re-extracted particles after a 3D refinement), set this flag to NO and in addition set the flag **Skip the prealignment step** to **YES.**

Note that setting flag **Read shifts from header** (see below) to **YES** turns off the initial 2D pre-alignment.

|||ITEMNOTEEND|||

|||ITEM||| **Starting resolution \[A\]:** 25.0

|||ITEMNOTE|||

The initial **VIPER** model will be low-pass filtered to this resolution to mitigate the initial model bias.

|||ITEMNOTEEND|||

|||ITEMTIP|||

Be careful if you use an X-ray derived structure as a starting reference. In this case, you should apply a stronger low-pass filter (for example to |||SI|||40 angstrom|||SIEND||| to |||SI|||50 angstrom|||SIEND|||).

|||NEWLINE|||

On the other hand, note that, based on the overall shape of the particle, too restrictive initial filtration may suppress discernible features and the program might fail to converge properly.

|||ITEMTIPEND|||

|||ITEM||| **Initial angular sampling step \[Degrees\]:** 7.5

|||ITEMNOTE|||

Usually the default value of |||SI|||7.5 degree|||SIEND||| is reasonable to create sufficient number of reprojections for the initial global parameter search for almost every asymmetric and/or low symmetry structures with initial resolution of |||SI|||15 angstrom|||SIEND||| to |||SI|||25 angstrom|||SIEND|||.

Refinement of higher resolution initial models and/or structures with high point group symmetry may benefit from a smaller initial angular sampling step, but values lower/equal than |||SI|||3.75 degree|||SIEND||| may result in excessively long time of calculations.

|||ITEMNOTEEND|||

|||ITEM||| **Particle radius \[Pixels\]:** 145

|||ITEM||| **3D mask:** 3DMask/sp\_mask\_mask.hdf

|||ITEMNOTE|||

This is the 3D mask produced in the previous step.

|||ITEMNOTEEND|||

|||ITEM||| **Point-group symmetry:** C5

|||ITEM||| **Memory per node \[GB\]:** 80

|||ITEMNOTE|||

Depends on cluster specifications. The program has to know the amount of physical memory available on each node as it uses “per node” |||MPI||| parallelization.

Nodes are basic units of a cluster, and each node has a number of processors.

While clusters are often characterized by the amount of memory per processor, here we ask for the total amount of **Memory per node \[GB\]** as the program will internally adjust the number of processors it is using.

For example, a cluster that has |||SI|||3 giga byte|||SIEND||| memory per processor and 16 processors per node has |||SI|||3 giga byte|||SIEND||| |||TIMES||| 16 = |||SI|||48 giga byte|||SIEND||| memory per node.

It is advisable to use a lower value (about |||SI|||20 percent|||SIEND|||) as at least some part of the memory of a node is not available to the program.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

|||IMPORTANT|||

Listed below are advanced options; please do not change their default values unless you understand their meaning well.

|||IMPORTANTEND|||

Advanced parameters:

|||ITEMIZEGUI|||

|||ITEM||| **Search range \[Pixels\]:** 5.0

|||ITEM||| **Search step size \[Pixels\]:** 1.0

|||ITEMNOTE|||

Changing the two values above can cause problems.

Increasing the initial search range and step might result in an unexpectedly long execution time.

Decreasing the range and step may cause the program to underperform.

Decreasing the range and step is justified only in cases when previously determined orientation parameters are available.

|||ITEMNOTEEND|||

|||ITEM||| **Correlation peaks to be included \[%\]:** 99.9

|||ITEMNOTE|||

**MERIDIEN** will computationally match each image with template reprojections of the structure and convert their similarity into probability values.

For high quality data and good agreement of the data with the initial model we want to include all computed probabilities as this assures the best performance of the program.

However, for lower quality data, the number of non-zero probabilities (and thus the "smear" of the correlation peak) might be excessively large and the running time of the 3D reconstruction step might increase excessively.

Should that happen, it is advisable to terminate the program and lower the value of this parameter.

|||SI|||0.0 percent|||SIEND||| value corresponds to usage of one orientation per image, thus "hard matching" refinement.

While this setting will result in a very fast execution of the program, the result will be most likely disappointing.

We found that for challenging cases, setting of this parameter to |||SI|||90 percent|||SIEND||| to |||SI|||95 percent|||SIEND||| provides a good balance between the runtime and the quality of the final result.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Specify the number of processors (on our cluster that has 24 processors per node, we used 48 processors) and submit the job to the queuing system of the cluster using an appropriate submission script by clicking the ***Run command*** button.

3D structure refinement with **MERIDIEN** is computationally expensive and the running time increases significantly with the number of particles and the box size.

|||NEWLINE|||

The refinement progresses through a sequence of search modes: **INITIAL**, **PRIMARY**, **EXHAUSTIVE**, **RESTRICTED**, and **FINAL**.

The main distinction is between **EXHAUSTIVE** searches, in which every data image is matched with all quasi-evenly generated reprojections of the model, and **RESTRICTED**, in which matching is done only within the neighborhood of orientation determined in the previous iteration.

The program uses elements of the Maximum Likelihood machinery.

**MERIDIEN** is driven by the internal assessment of the resolution between two quasi-independent concurrent refinements.

The current resolution is then used to set main parameters of the refinement process (i.e., angular step, shift search range, maximum resolution and thus the window size) using a set of simple heuristics.

In order to prevent premature termination at a suboptimal resolution stage, the program also uses heuristic randomization of the refinement process.

Thus, repeated runs of the program from the same starting point might yield slightly different results, both in terms of orientation parameters and the ultimate resolution.

One can monitor the progress of the job through the standard output, which will provide valuable information about the refinement.

For example, during every iteration, the program will print the time it took to process a chunk of |||SI|||20 percent|||SIEND||| of data.

Based on that, one can easily estimate the remaining time for the respective iteration.

|||STDOUT|||

Number of images : 9 48 18.8% 0.0min

|||STDOUTEND|||

In order to quickly check the progress of the run and the resolution from iteration to iteration, type:

|||TERMINAL|||

grep ITERATION my\_standard\_outputfile

|||TERMINALEND|||

|||NOTE|||

The name of the text file containing the standard output depends on your submission script.

|||NOTEEND|||

|||STDOUT|||

2019-05-09 14:38:38 main =\> **ITERATION** \# 1. Current state: INITIAL, nxinit: 52, delta: 7.5000, xr: 5.0000, ts: 1.0000

|||NEWLINE|||

2019-05-09 14:39:38 main =\> Resolution achieved in **ITERATION** \# 1: 16/ 26 pixels, 25.08A/15.43A.

|||NEWLINE|||

2019-05-09 14:39:38 main =\> **ITERATION** \# 2. Current state: PRIMARY, nxinit: 120, delta: 7.5000, xr: 5.0000, ts: 1.0000

|||NEWLINE|||

2019-05-09 14:40:56 main =\> Resolution achieved in **ITERATION** \# 2: 34/ 46 pixels, 11.80A/ 8.72A.

|||NEWLINE|||

2019-05-09 14:40:56 main =\> **ITERATION** \# 3. Current state: PRIMARY, nxinit: 102, delta: 7.5000, xr: 5.0000, ts: 1.0000

|||NEWLINE|||

2019-05-09 14:42:04 main =\> Resolution achieved in **ITERATION** \# 3: 37/ 47 pixels, 10.85A/ 8.54A.

|||NEWLINE|||

2019-05-09 14:42:04 main =\> **ITERATION** \# 4. Current state: PRIMARY, nxinit: 108, delta: 7.5000, xr: 5.0000, ts: 1.0000

|||NEWLINE|||

2019-05-09 14:43:14 main =\> Resolution achieved in **ITERATION** \# 4: 37/ 47 pixels, 10.85A/ 8.54A.

|||NEWLINE|||

2019-05-09 14:43:14 main =\> **ITERATION** \# 5. Current state: PRIMARY, nxinit: 108, delta: 7.5000, xr: 5.0000, ts: 1.0000

|||NEWLINE|||

2019-05-09 14:44:24 main =\> Resolution achieved in **ITERATION** \# 5: 37/ 46 pixels, 10.85A/ 8.72A.

|||NEWLINE|||

2019-05-09 14:44:24 main =\> **ITERATION** \# 6. Current state: EXHAUSTIVE, nxinit: 108, delta: 3.7500, xr: 4.1276, ts: 0.9663

|||NEWLINE|||

2019-05-09 14:48:59 main =\> Resolution achieved in **ITERATION** \# 6: 46/ 58 pixels, 8.72A/ 6.92A.

|||NEWLINE|||

2019-05-09 14:48:59 main =\> **ITERATION** \# 7. Current state: EXHAUSTIVE, nxinit: 126, delta: 3.7500, xr: 4.1276, ts: 0.9663

|||STDOUTEND|||

The printout contains a sequence of pairs of lines for each iteration.

They contain information about the time the iteration started, its number and the resolution achieved, both in Fourier |||UNIT|||pixels|||UNITEND||| and in |||UNIT|||angstrom|||UNITEND||| as read from driver |||FSC|||@0.5 and |||FSC|||@0.143.

Note that the so-called driver |||FSC||| is computed during the individual iterations and thus the printed resolutions are not the ultimate results but merely approximations calculated quickly for expediency to guide the program and used for adjustment of its parameters.

|||STDOUT|||

2019-05-09 14:51:34 main =\> **ITERATION** \# 9. Current state: EXHAUSTIVE, nxinit: 128, delta: 3.7500, xr: 4.1276, ts: 0.9663

2019-05-09 14:52:56 main =\> Resolution achieved in **ITERATION** \# 9: 46/ 59 pixels, 8.72A/ 6.80A.

|||STDOUTEND|||

For example, the line above informs us that ITERATION number 9 involved exhaustive searches and the parameters used were: processing window size (**nxinit**) 128, angular step (**delta**) |||SI|||3.75 degree|||SIEND|||, translational search range (**xr**) |||SI|||4.1276 pixels|||SIEND|||, and search step (**ts**) |||SI|||0.9663 pixels|||SIEND|||.

|||NEWLINE|||

You can also follow the progress of the refinement, and plot the driver |||FSC||| for each iteration using the **3D Refinement Assessment** |||GUI|||.

For this purpose, click the ***Refinement Assessment*** button in the middle:

|||FIGUREGUI|||08\_gui\_assessment.png|||FIGUREGUIEND|||

and then click the **Run command** button.

In the pop-up window select the current refinement directory (**Refine3D**):

|||FIGUREMEDIUM|||08\_assessment\_choose.png|||FIGUREMEDIUMEND|||

After clicking the ***Choose*** button, the program will display a plot of two curves showing resolution as a function of iteration number, as determined by the |||FSC|||@0.143 and |||FSC|||@0.5 criteria, respectively.

During runtime the plot will only include information about completed iterations.

Once a new iteration is finished, a pop-up window will prompt you to update the plot.

|||FIGURESMALL|||08\_assessment\_resolution.png|||FIGURESMALLEND|||

To display the driver |||FSC||| of a specific iteration, first check its tick box (i.e., **main003**) at the main window of the **Refinement Assessment** |||GUI|||, click the ***Plot*** button and then select the ***New*** ***FSC*** ***Plot*** option.

|||FIGUREMEDIUM|||08\_assessment\_fsc.png|||FIGUREMEDIUMEND|||

|||NOTE|||

Again, please keep in mind the driver |||FSC|||@0.143 and driver |||FSC|||@0.5 computed during the individual iterations do not reflect the final results.

|||NOTEEND|||

|||TIP|||  
When we monitor the progress of the refinement, we usually examine the half-maps for selected iterations in **UCSF Chimera**.

The nominal improvement in resolution should agree well with the visual appearance of the maps.

Note that these maps are not meant for interpretation yet, as they are merely approximations internally used by the program.

Thus, you should not attach too much weight to their appearance and, in particular, to the apparent lack of details.

Only the so-called “final” maps can be properly interpreted (see below for instructions how to compute them).

If one is impatient to examine the details without waiting for the refinement to complete, one can enhance the details using the **PostRefiner** tool in single volume mode that is available in the main **UTILITIES** section of the |||GUI|||.

|||TIPEND|||

|||FIGUREGUI|||08\_models.png|||FIGUREGUIEND|||

Once the program converged, it will print a notification and then calculate the final unfiltered, full size structures:

|||STDOUT|||

2018-03-01\_11:19:12 =\> Convergence criterion A is reached (angular step delta smaller than\\\\ 3/4 changes in angles))

|||NEWLINE|||

2018-03-01\_11:19:12 =\> Resolution achieved in ITERATION \#34: 48/ 97 pixels, 8.36A/ 4.14A.

|||STDOUTEND|||

The final half-volumes are stored in:

|||NEWLINE|||

**Refine3D/vol\_0\_unfil\_|||REDNUM|||iternr|||REDNUMEND|||.hdf** and **Refine3D/vol\_1\_unfil\_|||REDNUM|||iternr|||REDNUMEND|||.hdf**.

|||NEWLINE|||

The final orientation parameters are stored in

|||NEWLINE|||

**Refine3D/final\_params\_|||REDNUM|||iternr|||REDNUMEND|||.txt**.

|||ISSUE|||{\!Known issue in SPHIRE 1.3\!}

The last iteration is memory intensive and the run may crash if sufficient memory is not available. Check the **MEMORY ESTIMATION** entry for the final iteration in the **MERIDIEN** log file.

|||STDOUT|||

2019-05-09 17:43:49 recons3d\_final =\> MEMORY ESTIMATION. memory per node = 120.0GB, volume size = 2.12GB, data size per node = 0.91GB, estimated number of CPUs = 23.96

|||NEWLINE|||

2019-05-09 17:43:49 do3d\_final =\> do\_final\_rec3d

|||STDOUTEND|||

In this case Meridien estimated it required

|||EQUATION|||

|||SI|||24 giga byte|||SIEND||| |||TIMES||| 0.91 + |||SI|||2.12 giga byte|||SIEND||| = |||SI|||23.96 giga byte|||SIEND|||

|||EQUATIONEND|||

and the available memory per node was set to |||SI|||80 giga byte|||SIEND|||, thus the program assumes there is sufficient memory to calculate the final full-size 3D reconstruction.

|||NEWLINE|||

If the program crashes due to insufficient memory, try to perform the final reconstruction with the memory per node parameter set to a smaller value (**final 3D reconstruction only**, **ALTERNATIVES**).

|||NEWLINE|||

If the program does not finalize even if it uses only one processor per node, you have two options:

|||ENUMERATE|||

|||ITEM||| Reduce the size of input particles (and reference volume) by scaling them down. This can be done with the following command:

|||TERMINAL|||

sp\_process.py bdb:inputstack bdb:outputstack --changesize --ratio=0.8

|||TERMINALEND|||

This will reduce window size to **nx** |||TIMES||| 0.8, but has the undesirable associated effect of increasing the pixel size by a factor of 1.0 / 0.8 = 1.25, thus increasing the maximum/Nyquist frequency by the same factor.

It is also likely that due to the larger pixel size the alignment accuracy will decrease.

|||ITEM||| Further “clean” your dataset with an additional, more conservative **ISAC2** round, by setting the **Pixel error threshold \[Pixels\]** parameter of **ISAC2** to a lower value.

In general, refinements of “cleaner” stacks have lower average smear, run faster and require less memory.

|||ENUMERATEEND|||

|||ISSUEEND|||

|||NOTE|||

The actual number of iterations varies from run to run and depending on the number of the iteration with the highest resolution, the parameter file might have a different file name; so, please check the content of Refine3D directory, and use the proper number.

|||NOTEEND|||

On our cluster this **MERIDIEN** job, running on 48 processors, required about |||SI|||3 hours|||SIEND||| to finish.

If there is not enough time to perform the 3D refinement, please copy our pre-calculated results to the **project directory**.

|||TERMINAL|||

cp -r SphireDemoResults/Refine3D ./

|||TERMINALEND|||

|||NOTE|||

Should a **MERIDIEN** run into a time limit on your cluster or crash, you can simply restart it. For this purpose, first click in the main window of the |||SPHIRE||| |||GUI||| the button **MERIDIEN** on the left, then the **3D Refinement Restart** button within the **ALTERNATIVES** subsection in the middle and specify the **MERIDIEN** run directory (**Refine3D**).

Within the specified directory, the program will automatically identify, the last fully completed iteration automatically and continue from there.

|||NOTEEND|||

|||NOTE|||

It is possible to change some of the refinement parameter values upon a restart, but we do not encourage experimenting with the settings.

The reason is that |||ML||| refinement is an iterative process and by changing the parameters in the middle of the process, we modify the state of the program and this may have unintended consequences.

|||NOTEEND|||

Now we can use the ***Angular Distribution*** utility to produce a graphics file (*.bild*) with the angular distribution of your particles.

Click the ***Angular Distribution*** button (**UTILITIES**) in the middle of the |||SPHIRE||| |||GUI|||.

Fill out the following fields:

|||FIGUREGUI|||08\_ang\_dist.png|||FIGUREGUIEND|||

|||ITEMIZEGUI|||

|||ITEM||| **Projection parameters file:** Refine3D/final\_params\_**|||REDNUM|||**iternr**|||REDNUMEND|||**.txt

|||ITEM||| **Output directory:** Refine3D-angdist

|||ITEMIZEGUIEND|||

Click the ***Run command*** button and wait for the program to finish.

|||NOTE|||

If you did not set the ***Project Settings*** described in chapter \\nameref{PROJECT} you need to set the values for **Point-group symmetry**, **Pixel size \[A\]** (**Advanced**) and **Box size \[Pixels\]** (**Advanced**) manually.

|||NOTEEND|||

|||NOTE|||

To learn more about angular distribution visualization, visit the wiki page |||URL|||http://sparx-em.org/sparxwiki/Euler\_angles|||URLEND|||.

|||NOTEEND|||

Wait for the program to finish and then load one of the half volumes\\\\ (i.e., **Refine3D/vol\_0\_unfil\_|||REDNUM|||iternr|||REDNUMEND|||.hdf**) together with the resulting *.bild* file into **UCSF Chimera**.

|||FIGUREMEDIUM|||08\_ang\_dist\_vol.png|||FIGUREMEDIUMEND|||

The resulting *VRML model* in **UCSF** **Chimera** will illustrate the number of particle images assigned to given orientation directions within one asymmetric unit of angular space, as defined by the **Point-group symmetry**.

Note this display only contains the distribution of the most probable orientations assigned to the data, as determined by the Maximum Likelihood methodology employed by **MERIDIEN**.

Therefore, the picture is somewhat misleading as the actual distribution of angular information may be significantly different.

The full information about all orientation parameters is stored in each **Refine3D/main|||REDNUM|||ITERNR|||REDNUMEND|||/oldparamstructure**.

However, at this time we do not have any utilities that would allow the examination of this information in a compact form.

|||NEWLINE|||

Make sure that the visualized angular distribution is not dominated by just a few directions (especially if you process an asymmetric particle).

In such a case, the reconstructed structure will likely have directional artifacts (e.g. elongation in real space).

|||TIP|||

If the data were already subjected to 3D refinement and 3D orientation parameters (shifts and Euler angles) are available, you can use the already determined parameters to start a local refinement (***MERIDIEN**/**ALTERNATIVES**/**Local Refinement from Stack***).

The local 3D refinement is designed to refine a structure with user-provided orientation parameters taken to initialize the iterative process.

This program will do only local searches and it begins with 3D reconstruction of initial reference half-maps.

|||TIPEND|||

In order to initiate the local refinement (or 3D sorting; see section below), input images should have 3D orientation parameters stored in headers.

Alignment parameters from a **MERIDIEN** are imported to the header of the particle using the **Import projection parameters** tool **(Alternatives)**.

|||TIP|||

If you refined your data using **RELION** you can easily convert the files and create a particle stack in BDB file format using the ***UTILITIES**/**RELION to SPHIRE conversion*** tool.

The particle stack will contain alignment parameters stored in its header and you will be able to directly continue with |||SPHIRE||| and to perform a local 3D refinement and/or 3D sorting using the imported data.

|||TIPEND|||

|||SECTION|||PostRefiner|||SECTIONEND|||

This utility executes the following sequence of operations: calculation of a soft 3D mask, estimation of the |||FSC||| using masked half-maps with |||FSC||| rescaling to account for the full-size of the dataset \\parencite{Penczek:2010me}, merging of two half-maps, |||MTF||| compensation, filtration by the |||FSC|||, estimation of the B-factor from the merged map, high-pass filtration of the merged map using a B-factor-parametrized Gaussian function (B-factor is either estimated by the program or defined by the user), and low-pass filtration (either at the estimated resolution or at a cut-off resolution chosen by the user).

Some of the operations listed are optional.

The output of the utility is a power spectrum-adjusted map both with and without masking being applied.

Finally, the program reports the resolution values of |||FSC|||@0.5 and |||FSC|||@0.143.

|||NEWLINE|||

In the main window of the |||SPHIRE||| |||GUI||| first click the button ***MERIDIEN*** on the left, then the ***PostRefiner*** button in the middle and fill out the following input fields:

|||FIGUREGUI|||08\_gui\_post\_refine.png|||FIGUREGUIEND|||

|||ITEMIZEGUI|||

|||ITEM||| **First unfiltered halfset volume:** Refine3D/vol\_0\_unfil\_**|||REDNUM|||**iternr**|||REDNUMEND|||**.hdf

|||ITEMNOTE|||

Click the ***Select HDF volume*** button, and use the file browser to select the first final half-volume.

|||ITEMNOTEEND|||

|||ITEM||| **Second unfiltered halfset volume:** Refine3D/vol\_1\_unfil\_**|||REDNUM|||**iternr**|||REDNUMEND|||**.hdf

|||ITEMNOTE|||

Click the ***Select HDF volume*** button, and use the file browser to select the second final half-volume.

|||ITEMNOTEEND|||

|||ITEM||| **Output directory:** Sharpening-after-meridien

|||ITEM||| **Pixel size \[A\]:** 1.14

|||ITEM||| **3D mask file:** none

|||ITEMNOTE|||

Usually we automatically compute a 3D mask, using a 3D adaptive mask procedure (see below).

If you want to skip this and use a 3D mask obtained by a different method instead, use the file browser to load your 3D mask file and deactivate the apply adaptive mask option below.

|||ITEMNOTEEND|||

|||ITEM||| **Apply adaptive mask**: YES

|||ITEMNOTE|||

Activation of this option will create a 3D mask directly from the combined half-maps guided by the user-defined parameters listed below.

|||ITEMNOTEEND|||

|||ITEMNOTE|||

Setting of **3D mask file** to **none** and **Apply adaptive mask** to **NO**, will completely deactivate 3D masking.

In this case the final output will be power spectrum adjusted but not masked and the |||FSC||| will be computed between the two unmasked half-volumes.

|||ITEMNOTEEND|||

|||ITEM||| **Binzarization threshold:** 0.02

|||ITEMNOTE|||

Open one of the half-volumes in **UCSF Chimera** and visually establish a proper threshold value.

The density map should not show any disconnected regions.

|||ITEMNOTEEND|||

|||ITEM||| **Soft edge width \[Pixels\]:** 5

|||ITEM||| **Dilation width \[Pixels\]:** 3

|||ITEM||| **|||MTF||| file:** FalconIImtf.txt

|||ITEMNOTE|||

Providing an |||MTF||| file name will activate |||MTF||| compensation.

Click the ***Select MTF data*** button, and use the file browser to select the |||MTF||| file that comes along with our test data set for the Falcon II detector at |||SI|||300 kilo volt|||SIEND||| (stored in the **project directory**).

|||ITEMNOTEEND|||

|||ITEM||| **B-Factor enhancement:** 0

|||ITEMNOTE|||

Set to 0, in order to estimate and apply B-factor automatically.

|||NEWLINE|||

Alternative Options:

**-1:** Do not apply B-factor.

|||NEWLINE|||

**Positive number:** 128 (a user specified B-factor of |||SI|||128 angstrom^2|||SIEND||| will be applied.

|||ITEMNOTEEND|||

|||ITEMNOTE|||

By default, the program will estimate B-factor in |||SI|||10 angstrom|||SIEND||| to full resolution range.

You can adjust the B-factor estimation range in the advanced options.

|||ITEMNOTEEND|||

|||ITEM||| **Low-pass filter frequency \[A\]:** 0

|||ITEMNOTE|||

Cut-off resolution to filter the final map.

Set to 0 to filter the map according to |||FSC|||@0.143.

|||NEWLINE|||

Alternative options

|||NEWLINE|||

**Positive value:** 5.8 (low pass filter to |||SI|||5.8 angstrom|||SIEND|||.)

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Click the ***Run command*** button.

|||NEWLINE|||

Monitor the progress of the job at the terminal through the logfile **log.txt**:

|||TERMINAL|||

tail –f Sharpening-after-meridien/log.txt

|||TERMINALEND|||

The output looks like this:

|||STDOUT|||

2019-05-13 16:14:48 logLine =\> ---------- \>\>\> Summary \<\<\<------------

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> Final resolution 0.5/0.143 is 4.14/ 3.43\[A\]

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> B-factor is -56.03\[A^2\]

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> FSC curves are saved in halves.txt, full.txt, masked\_halves.txt, masked\_full.txt

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> The final volume is Sharpening-after-meridien/vol\_combined.hdf

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> Guinierlines in logscale are saved in Sharpening-after-meridien/guinierlines.txt

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> Tanl low-pass filter is applied using cutoff frequency 1/ 3.43\[1/A\]

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> ----\>\>\> Analysis of enhancement \<\<\<-----

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> B\_factor : 56.026815

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> Low-pass filter cutoff : 3.429743\[A\] (0.332386\[absolute\])

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> Low-pass filter falloff : 0.010000\[absolute\]

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> Max enhancement point : 115\[pixels\]

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> Max enhancement ratio : 33.665805

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> First zero pw spectrum point : 132\[pixels\]

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> Falloff width : 17\[pixels\]

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> -------------------------------------------------------

|||NEWLINE|||

2019-05-13 16:14:48 logLine =\> ---------- \>\>\> DONE \<\<\< ------------

|||STDOUTEND|||

On our Linux cluster, this program job finished after few seconds.

|||NEWLINE|||

However, if you do not have enough time to wait for the results, you can find the precalculated results for this step in the folder **SphireDemoResults/Sharpening-after-meridien**.

|||NEWLINE|||

In our case, according to the masked |||FSC|||@0.143, the final map has a resolution of |||SI|||3.43 angstrom|||SIEND|||.

A B-factor of |||SI|||−56 angstrom^2|||SIEND||| and a low-pass filter at |||SI|||3.5 angstrom|||SIEND||| were thus applied to the map.

In the output directory you can now find the following files:

|||ITEMIZEDASH|||

|||ITEM||| **vol\_combined.hdf:** The merged, sharpened and masked final structure, filtered to the achieved resolution of |||SI|||3.5 angstrom|||SIEND|||.

|||ITEM||| **vol\_combined\_nomask.hdf:** The final structure, with no mask applied.

|||ITEM||| **vol\_adaptive\_mask.hdf:** The soft 3D mask used for the |||FSC||| calculations.

|||ITEM||| **fsc.png:** A plot of all |||FSC||| curves.

|||ITEMIZEDASHEND|||

The program will also output text files for all |||FSC||| curves and the Guinier plot.

Display the final structure using **UCSF Chimera** and check the |||FSC||| plots carefully (see note below).

Compare the |||ELM||| map with the available X-ray structure.

|||FIGUREMEDIUM|||08\_fsc.png|||FIGUREMEDIUMEND|||

|||NOTE|||

As is well known, the application of a very tight mask may result in an overestimation of resolution. While in general this effect is impossible to avoid (short of not using any mask at all), one has to take precautions to avoid an excessive impact of the mask.

Examine the |||FSC||| curve carefully. If the |||FSC||| curve rises in high frequencies or it never drops below zero, repeat the |||FSC||| estimation using a more generous mask.

Another telltale sign is emergence of strange B-factor values estimated by the program and/or high-resolution artifacts in the map.

Ideally, right after it drops to 0.143, the |||FSC||| should oscillate around the zero line.

For an in-depth discussion and more examples see \\parencite{Penczek:2010me}.

|||NOTEEND|||

|||TIP|||

You should always visually inspect the resulting map and confirm that the features of the density agree with the nominal resolution (i.e., a high-resolution map should show clearly discernible side chains).

You can also simply download atomic coordinates of an X-ray crystallographic structure, convert them to a pseudo-electron density map using box and pixel size of the map in question (***PDB File Conversion*** in ***UTILITIES***) and apply a low-pass filter using the same cut-off resolution as the one determined in the post-refinement step.

The appearance of surfaces, as visualized by **UCSF Chimera**, should be similar between the |||ELM||| map and the converted X-ray model.

In particular, spurious surface features, strange sharpness of the surface, disconnected pieces, and/or lack of secondary features that at the same time are discernible in X-ray map, set a red flag.

Conversely, an exceedingly smooth appearance of the |||ELM||| map means that either its resolution and/or the B-factor were underestimated.

|||TIPEND|||

|||IMPORTANT|||

Scaling of the |||FSC||| (**FSC masked full**) is still an experimental feature under development and might report higher resolutions.

Check the output structure carefully – report only the resolution according to the |||FSC|||@0.143 of the **masked halves** curve.

|||IMPORTANTEND|||

Results of the 3D refinement highly depend on the quality of the initial model.

Therefore, we usually recommend starting a second round of 3D refinement using the newly produced, sharpened volume as the initial reference, as well as the 3D mask obtained by the **PostRefiner** utility.

This may improve resolution of the newly refined structure.

|||FIGUREMINI|||08\_final.png|||FIGUREMINIMIDDLE|||Congratulations\!\\\\You produced your first near-atomic resolution reconstruction\\\\with\\\\\\medskip {\\Huge\\sphire}|||FIGUREMINIEND|||

|||CHAPTERBROWN|||SORT3D|||CHAPTERSORT|||

|||SECTION|||3D Variability|||SECTIONEND|||

After the 3D structure refinement is completed, we assess possible structural variability of the complex.

3D variability might be caused by conformational changes, substoichiometric ligand binding and/or compositional heterogeneity.

In general, regions with higher variability are less reliable and the data may require further analysis.

In order to detect such regions, we calculate a 3D variability map using the |||ELM||| image data and their orientation parameters.

|||TIP|||

Although regions with higher variability typically show fewer details, this step is not done to estimate the local resolution, but it is rather used to guide the subsequent step of 3D sorting.

|||SPHIRE||| includes a dedicated tool for the local resolution estimation (**LOCALRES**), which is usually performed at the end of the workflow, as described below.

|||TIPEND|||

|||NOTE|||

Ideally, we would want to compute a 3D variance map using the projection data.

However, it is not immediately apparent that this is mathematically possible as the data is given in form of projections.

Moreover, methods suggested in the literature call for massive calculations.

Therefore, in |||SPHIRE||| we settle for a good approximation of the variance map, that we termed “variability map”.

|||NOTEEND|||

First, we will import the orientation parameters of the final refinement iteration (with the highest resolution) to the header of the clean particle stack (the particle stack created after **ISAC2**, that we used as input for the 3D refinement).

|||NEWLINE|||

In the main window of the |||SPHIRE||| |||GUI||| click the button ***SORT3D*** on the left and then the ***Import Projection Parameters*** button in the middle:

|||FIGUREGUI|||09\_gui\_projection\_parameters.png|||FIGUREGUIEND|||

Fill out the following input fields:

|||ITEMIZEGUI|||

|||ITEM||| **Import parameters:** Refine3D/final\_params\_**|||REDNUM|||**iternr**|||REDNUMEND|||**.txt

|||ITEMNOTE|||

Click the ***Select parameters text*** button, and use the file browser to select the text file with the orientation parameters of the refinement iteration with the highest resolution.

|||ITEMNOTEEND|||

|||ITEM||| **Input image stack:** bdb:Substack\#isac\_substack

|||ITEMNOTE|||

Click the ***Select BDB image stack*** button, and use the file browser to select the stack used as input for the high-resolution refinement.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

|||NOTE|||

During the 3D refinement, **MERIDIEN** outputs, and uses multiple projection directions (probability-weighted) per particle.

However, for the purpose of variability analysis, we use only the highest-probability orientations for each particle.

|||NOTEEND|||

Click the ***Run command*** button.

|||NEWLINE|||

In the next step, we will perform a “symmetrization” of this dataset in order to cover the entire 3D angular space for the subsequent calculation of the 3D variability field.

|||TIP|||

If you are processing an asymmetric particle, please skip this step and proceed directly to the 3D Variability estimation.

|||TIPEND|||

In the main window of the |||SPHIRE||| |||GUI||| first click the button ***SORT3D*** on the left and then the ***3D Variability Preprocess*** button in the middle:

|||FIGUREGUI|||09\_gui\_var\_preprocess.png|||FIGUREGUIEND|||

Fill out the following input fields:

|||ITEMIZEGUI|||

|||ITEM||| **Input image stack:** bdb:Substack\#isac\_substack

|||ITEMNOTE|||

Click the ***Select BDB image stack*** button, and use the file browser to select the stack used as input for the high-resolution refinement.

|||ITEMNOTEEND|||

|||ITEM||| **Output directory:** Symstack

|||ITEM||| **Point-group symmetry:** C5

|||ITEMIZEGUIEND|||

A symmetrized dataset named **bdb:Symstack\#sdata** will then be stored directly in the output directory.

(This is a virtual stack, so no excessive amount of disk space is consumed).

Use **EMAN2**’s **e2iminfo.py** to check the number of particles in this dataset.

|||TERMINAL|||

e2iminfo.py bdb:Symstack\#sdata

|||TERMINALEND|||

After “symmetrization” (C5 symmetry is used in our example) this stack should contain five times more projections than your input dataset (5 × 10949 = 54745 particles).

|||NEWLINE|||

In the main window of the |||SPHIRE||| |||GUI||| click the button ***3D Variability*** Estimation in the middle:

|||FIGUREGUI|||09\_gui\_var\_est.png|||FIGUREGUIEND|||

Fill out the following input fields:

|||ITEMIZEGUI|||

|||ITEM||| **Input image stack:** bdb:SymStack\#sdata

|||ITEMNOTE|||

Click the ***Select BDB image stack*** button, and use the file browser to select the symmetrized stack located in the **SymStack** project directory.

|||ITEMNOTEEND|||

|||ITEMNOTE|||

After the successful 3D refinement, projection parameters are now available for each particle. The program will find and borrow its neighbors (the size of the angular neighborhood is user-defined) and will compute average and variance using this grouping.

During this tutorial, we will not output these 2D averages and variances, as they consume a large amount of disk space and are not particularly interesting per se. The program will, however, use them to produce a 3D average and variability map (see below).

If you do want to output the intermediate 2D results, activate the relevant option in the advanced parameters. Both the averages and variances will have 3D orientation parameters stored in headers, so you can compute 3D maps independently. Note that both averages and variances are CTF-corrected, so they do not have CTF information stored in headers.

|||ITEMNOTEEND|||

|||ITEM||| **Output directory:** 3DVAR

|||ITEM||| **Output 3D variability:** 3dvar.hdf

|||ITEMNOTE|||

3D variability map.

|||ITEMNOTEEND|||

|||ITEM||| **Output 3D average:** 3davg.hdf

|||ITEMNOTE|||

3D map computed from neighbor-based 2D averages.

|||ITEMNOTEEND|||

|||ITEM||| **Number of projections:** 10

|||ITEMTIP|||

The larger the number, the less noisy the variability map but the lower the resolution.

In general, you have to consider here the size of your dataset and the type of heterogeneity you expect and want to visualize and adjust this value accordingly. For larger datasets (more than 100.000 particles), increase the number of projections to 50-100.

|||ITEMTIPEND|||

|||ITEM||| **Point-group symmetry:** C5

|||ITEM||| **Use |||CTF|||:** YES

|||ITEMTIP|||  
If YES, the program will use CTF correction during calculation of both 2D averages and variances.

Deactivate this flag for negative-stain data.

For negative stain data, variability analysis is more challenging and should be performed only if one expects compositional heterogeneity of large-molecular-weight components or very large and well-defined conformational changes.

To further enhance the results, consider restricting analysis of the variability to data extracted from micrograph areas of similar stain thickness.

|||ITEMTIPEND|||

|||ITEMIZEGUIEND|||

Advanced parameters:

|||ITEMIZEGUI|||

|||ITEM||| **Image decimate factor:** 0.25

|||ITEMNOTE|||

Very large datasets with large box sizes might fail due to insufficient memory. In addition, most conformational changes can be easily detected using a larger pixel size. Therefore, by default, the 2D averages and variances are binned 4x during the calculation of the 3D variability map (**decimate factor** of 0.25). If you wish, however, to detect the variability of high-resolution features (e.g. binding of small ligands) it might be necessary to increase the factor and adjust the pixel size accordingly.

|||ITEMNOTEEND|||

|||ITEM||| **Target image size \[pixels\]:** 290

|||ITEMNOTE|||

To further reduce memory consumption, you can in addition clip the images and use a smaller box size, without changing the pixel size. Make sure, however, that the new smaller box size is still slightly larger than the longest axis of the particle. By default, images are not clipped.

|||ITEMNOTEEND|||

|||ITEM||| **Low-pass filter frequency \[1/Pixel\]:** 0.0

|||ITEM||| **Low-pass filter fall-off \[1/Pixel\]:** 0.0

|||ITEMNOTE|||

In order to suppress noise, before the variability calculation, it is possible to apply a low-pass filter. By default, images are not filtered. Use the resolution pop-up converter (**Use resolution \[A\]**) to calculate resolution in |||UNIT|||angstrom|||UNITEND|||. If you binned your images (image decimate factor option), make sure to enter the new pixel size (original pixel size/decimate factor).

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Specify the number of processors (for this job we used 48) and submit the job to the queuing system of the cluster using an appropriate submission script by clicking the ***Run command*** button.

This process should finish after few minutes (or hours for larger datasets).

|||NEWLINE|||

The 3D average and variability volumes (**3davg.hdf**, **3dvar.hdf**) are located in the output directory **3DVAR**.

Display both maps in **UCSF Chimera**.

|||NEWLINE|||

Otherwise, to save time, you can copy the precalculated variance and average maps to the **project directory** and display them:

|||TERMINAL|||

cp -Rp SphireDemoResults/3DVAR ./

|||TERMINALEND|||

The average map and the simplified variability map are shown in gray and red, respectively.

The first observation is the high amount of noise in the variability map.

|||FIGUREMEDIUM|||09\_3dvar.png|||FIGUREMEDIUMEND|||

While there is some variability detected at the channel opening (binding domain of component A, see dashed line), the bulk of our tutorial particle can be considered rather rigid, so the 3D variability analysis yields rather limited information.

|||NEWLINE|||

Nevertheless, in order to demonstrate how to identify homogeneous subpopulations of particles, we will continue with a 3D heterogeneity analysis in the next section.

|||SECTION|||3D Clustering |||SECTIONEND|||

We will now perform a 3D cluster analysis of the 3D refined dataset using the **SORT3D** program.

In the protocol adopted in |||SPHIRE|||, we separate 3D refinement from 3D sorting of the data.

Thus, in a first step we refine the entire dataset using **MERIDIEN** (see previous section) assuming that it is relatively homogeneous, i.e., it does not contain different categories of macromolecular shapes (for example a mixture of ribosomes and proteasomes).

In particular, any heterogeneity or flexibility of the analyzed complex should be "secondary" with respect to the overall shape and thus it should make sense to initially treat all projections as belonging to one, quasi-homogeneous dataset.

The overall structure derived from **MERIDIEN** refinement should, to a degree, "make sense" and its reprojections should match the reference-free 2D class averages produced by **ISAC2**.

|||NEWLINE|||

Given these assumptions, we can now proceed with the next step, the clustering, which treats the orientation parameters as constant (i.e., there is no alignment during sorting).

In **SORT3D** we employ a variant of the *K*-means algorithm in which we maintain an approximately equal sizes for all sorted groups.

To provide validation of the outcome, the **SORT3D** program employs a strategy of multiple independent random restarts.

Thus, the program will actually perform clustering of the data multiple times using different random initializations (different initial structures), compare resulting group assignments and accept results only if they are above the level expected from chance sorting.

It follows that the outcome is validated in a sense of assuring the user that the results can be reproduced with reasonable certainty and are not random artifacts.

Finally, the program will output the results of statistical |||ANOVA||| tests designed to verify that the outcome of sorting is not influenced by parameters that are unrelated to the structure itself and, for example, avoid results that were sorted "by defocus", which regrettably is a relatively common artifact.

|||TIP|||

This step is computationally expensive, and the running time increases significantly with the number of particles and groups.

|||TIPEND|||

|||TIP|||

In other software packages, 3D sorting is sometimes performed to remove “junk” particles.

In |||SPHIRE|||, most of these particles have already been eliminated by **ISAC2** during 2D clustering.

|||TIPEND|||

In the main window of the |||SPHIRE||| |||GUI||| first click the button ***SORT3D**,* then the button ***3D Clustering from Iteration - SORT3D\_DEPTH*** in the middle and fill out the following fields:

|||FIGUREGUI|||09\_sort3d.png|||FIGUREGUIEND|||

|||ITEMIZEGUI|||

|||ITEM||| **Meridien run directory:** Refine3D

|||ITEMNOTE|||

Click the ***Select directory*** button, and use the file browser to select the 3D refinement directory.

|||ITEMNOTEEND|||

|||ITEMTIP|||

The program takes advantage of all of the |||ML||| information produced in the 3D reconstruction step **(MERIDIEN)** and will make use of the probability distributions associated with the individual particle images.

|||ITEMTIPEND|||

|||ITEM||| **Output directory:** Sort3D

|||ITEM||| **3D refinement iteration ID:** 28

|||ITEMNOTE|||

The **MERIDIEN** iteration number whose alignment parameters will be used by the program.

|||ITEMNOTEEND|||

|||ITEMTIP|||

The choice of iteration number depends on the goals set by the user.

It does not have to be the final iteration and in fact to select it is usually counterproductive as the last few iterations use a larger window size and, which results in longer runtimes of **SORT3D**.

For the same reason one should avoid iterations with large smear values.

Also, early iterations should not be used, including early **RESTRICTED** ones as the structure is not yet sufficiently formed to permit sensible sorting.

|||ITEMTIPEND|||

|||ITEM||| **3D mask:** 3DMask/sp\_mask\_mask.hdf

|||ITEMNOTE|||

This is the global mask used for the sorting procedure.

It should be always soft-edged.

For the tutorial dataset, the mask previously used in **MERIDIEN** 3D refinement is a good choice.

Click the ***Select HDF volume*** button, and use the file browser to select the soft 3D mask used during refinement.

However, we prefer to use a more generous mask here (not the 3D mask obtained during sharpening), because the heterogeneity revealed by the 3D variability analysis was not resolved in the refined map.

In general, tight masks should be avoided as one may inadvertently mask out an as yet undetected region of interest.

|||ITEMNOTEEND|||

|||ITEMTIP|||

When processing your own data display the 3D variability map, the refined map and the 3D mask together jointly in **UCSF** **Chimera**, to confirm that the soft 3D mask encloses the protein map completely (particularly any dynamic components that are not yet resolved in the refined map, but clearly present in the variability map).

|||ITEMTIPEND|||

|||ITEM||| **Focus 3D mask:** none

|||ITEMNOTE|||

A binary focus mask.

It is used to perform focused clustering.

It allows the user to focus sorting on a particular region of a 3D structure e.g. a flexible region, as discussed above.

In the case of the tutorial dataset, since the 3D variability map did not reveal any local heterogeneity (e.g. substoichiometric ligand binding, a flexible domain, etc.), we will not conduct any focused classification and thus set this input to "none".

|||ITEMNOTEEND|||

|||ITEMTIP|||

If the variability analysis indicates a clear local flexibility in the map, use the ***Masking*** utility and the **3D Variability map** as input**,** to create a focus mask for **SORT3D.** The focus mask has to be a **binary** mask; therefore set the **Soft edge width** option (**Masking**) to 0.

|||ITEMTIPEND|||

|||ITEM||| **Number of images per group:** 5470

|||ITEMNOTE|||

The entered value will be used to determine the initial number of groups, as given by the following relation:

|||EQUATION|||

\\text{Total Number of Particles} = \\frac{10949}{\\text{Particles per group}} = 5470\\approx 2\\,.

|||EQUATIONEND|||

However, the ultimate number of groups determined by the program depends on the heterogeneity of the dataset and may be either larger or smaller than the initial number.

In particular, if there is no reproducible clustering of the dataset, given user-settings, the program will terminate and only return a single group.

|||NEWLINE|||

The program will try to maintain groups of the size given by this parameter.

However, the ultimate group sizes will not necessarily be equal to the value used and can differ significantly.

In general, larger values will result in larger group sizes.

|||ITEMNOTEEND|||

|||ITEMIMPORTANT|||

The desired number of images per group has to be larger than the minimum group size set (the next parameter).

|||ITEMIMPORTANTEND|||

|||ITEMTIP|||

Adjust this parameter group size based on the size, resolution, and quality of your dataset, the available computational resources, and the goal of **SORT3D**.

The runtime will increase linearly with the number of groups.

|||ITEMTIPEND|||

|||ITEM||| **Minimum size of reproducible class:** 900

|||ITEMNOTE|||

The clusters determined by the program will have at least the number of images determined by the value of this parameter.

Smaller candidate clusters will be eliminated.

A minimum group size cannot be too small (for example 10), as it is impossible to compute a valid 3D structure from such a small number of images.

We recommend setting it to a large value without exceeding the desired group size.

|||ITEMNOTEEND|||

|||ITEM||| **Swap flag:** YES

|||ITEM||| **Swap percentage \[%\]:** 15

|||ITEM||| **Memory per node \[GB\]:** 100

|||ITEMIZEGUIEND|||

Specify the number of processors (for this job we used 96) and submit the job to the queuing system of your cluster using an appropriate submission script by clicking the ***Run command*** button.

|||NEWLINE|||

You can monitor the progress of the program by following the information that appears in the logfile **log.txt**.

|||TERMINAL|||

tail -f Sort3D/log.txt

|||TERMINALEND|||

On our cluster, this job finished in about |||SI|||75 minutes|||SIEND|||.

Otherwise, to save time, copy the precalculated results to the **project directory** and continue with those.

In this case, type:

|||TERMINAL|||

cp –Rp SphireDemoResults/Sort3D ./

|||TERMINALEND|||

The **SORT3D** results are reported at the end of the logfile (**log.txt**) saved in the output directory.

For each determined group, the printout states group ID, number of images assigned to the group, group reproducibility, group random reproducibility (based on Monte Carlo sampling), the standard deviation of the group random reproducibility, the name and the location of the group selection file, and finally the location and name of the map file of this group.

The logfile also contains information about the total number of images, the number of images in all groups (“accounted for” images) and the number of the images not assigned to any groups (“unaccounted for” images; the numbers of which is saved in the text file **Unaccounted.txt** in the output directory).

What follows are results of statistical |||ANOVA||| analysis computed for group defocus values, image norms per group, and the smearing (spread of probabilities per image) per group.

These results make it possible to determine whether the determined grouping of the data reflects factors other than structural heterogeneity.

Of particular interest here are the defocus values.

Should their average values differ significantly between groups, it is quite likely that the apparent structural differences are due to differences in group defocus values, and not due to actual differences in the respective structures.

|||NEWLINE|||

At the terminal type:

|||TERMINAL|||

cat Sort3D/log.txt

|||TERMINALEND|||

|||STDOUT|||

2019-05-17 16:36:53 logLine =\> Final results saved in Sort3D

|||NEWLINE|||

2018-03-05\_18:13:39 =\> ------------------------------

|||NEWLINE|||

2019-05-17 16:36:53 logLine =\> Group ID size determined in generation reproducibility random reproducibility std selection file map file

|||NEWLINE|||

2019-05-17 16:36:54 logLine =\> 0 6363 0 90.6 42.7 5.2 Cluster\_000.txt vol\_cluster000.hdf

|||NEWLINE|||

2019-05-17 16:36:54 logLine =\> 1 3929 0 85.7 28.9 5.7 Cluster\_001.txt vol\_cluster001.hdf

|||NEWLINE|||

2019-05-17 16:36:54 logLine =\> Images 10949 accounted for images: 10292 unaccounted for images: 657 |||NEWLINE|||

2018-03-05\_18:13:53 =\> Unaccounted images saved in Unaccounted.txt

|||STDOUTEND|||

From the above table we learn that out of 10949 images, the program assigned 10292 images (accounted for) to two groups (groups 0 and 1), containing 6363 and 3929 images respectively.

657 images were not assigned to any groups (unaccounted for images).

Due to the intrinsic randomness of the sorting algorithm, the numbers of images per group may slightly differ from one run to another.

|||NEWLINE|||

The final results table contains the results of internal reproducibility tests.

As the program performs independent clustering it is possible to compute the reproducibility of the individual groups obtained in these independent runs, in other words, computing the percentage of images that were assigned to the same group across different runs.

Here they are |||SI|||90.6 percent|||SIEND||| and |||SI|||85.7 percent|||SIEND|||, respectively.

In order to assess whether these reproducibility levels are above what one would expect if the assignments were entirely random, we perform **Monte Carlo** simulation using the group sizes as input.

The random reproducibility levels are |||SI|||42.7 percent|||SIEND||| and |||SI|||28.9 percent|||SIEND||| while their standard deviations are 5.2 and 5.7, respectively.

We set the group rejection threshold at random reproducibility plus its two standard deviations (which approximately corresponds to |||SI|||5 percent|||SIEND||| significance level) and remove those groups whose reproducibility is below this level.

Please note that at this level (and even at three $\\sigma$ level) all obtained groups are significantly more reproducible than what we would obtain if groups were due to random chance assignments, i.e., if in reality there were no groups in the data.

|||NEWLINE|||

The output logfile also contains the results of the statistical analysis of the possible influence of external parameters that are a source of data heterogeneity on the output of the sorting.

We will discuss analysis of variance of average defocus values per group, i.e., we want to determine whether the obtained groups differ by defocus.

If that was the case, the sorting result would be in question.

For this, the relevant part of the logfile is:

|||STDOUT|||

2019-05-17 16:37:05 logLine =\> ANOVA of defocus

|||NEWLINE|||

2019-05-17 16:37:05 logLine =\> ANOVA F-value Significance

|||NEWLINE|||

2019-05-17 16:37:05 logLine =\> ANOVA 0.00 100.00

|||NEWLINE|||

2019-05-17 16:37:05 logLine =\>

|||NEWLINE|||

2019-05-17 16:37:05 logLine =\> ANOVA: defocus mean of all clusters: 1.571500

|||NEWLINE|||

2019-05-17 16:37:05 logLine =\> ANOVA: Group averages

|||NEWLINE|||

2019-05-17 16:37:05 logLine =\> ANOVA GID N mean std

2019-05-17 16:37:05 logLine =\> ANOVA 0 106 1.5715 0.3673

|||NEWLINE|||

2019-05-17 16:37:05 logLine =\> ANOVA 1 106 1.5715 0.3673

|||NEWLINE|||

2019-05-17 16:37:05 logLine =\>

2019-05-17 16:37:05 logLine =\> ANOVA Pair-wise tests

|||NEWLINE|||

2019-05-17 16:37:05 logLine =\> ANOVA A B avgA avgB F\_value

Significance

|||NEWLINE|||

2019-05-17 16:37:05 logLine =\> ANOVA 0 1 1.5715 1.5715 0.000 100.0000

|||STDOUTEND|||

According of the results of the overall |||ANOVA||| of defocus, the differences are not significant. This is further confirmed by pair-wise tests and therefore we can reject the hypothesis that defocus influenced results of 3D sorting.

(Significance should be \<= 0.05 in order to reject null hypothesis of equality of defocus means).

|||NEWLINE|||

In the output directory, you can find following files:

|||ITEMIZEDASH|||

|||ITEM||| **Cluster\_|||REDNUM|||ITERNR|||REDNUMEND|||.txt**

|||ITEMNOTE|||

The numbered Cluster|||REDNUM|||ITERNR|||REDNUMEND|||.txt files contain the IDs of the particles assigned to the respective cluster.

|||ITEMNOTEEND|||

|||ITEM||| **vol\_cluster|||REDNUM|||ITERNR|||REDNUMEND|||.hdf**

|||ITEMIZEDASHEND|||

These are the volumes calculated from each cluster of images.

Note, however, that these are internal **SORT3D** maps (similar to half-maps stored for every iteration during **MERIDIEN** run in main|||REDNUM|||ITERNR|||REDNUMEND||| directories), i.e., during 3D reconstruction they were truncated at the maximum resolution of the refined input data.

Consequently, they will be featureless if displayed in **UCSF** **Chimera**.

If you wish to bring up some details, you can use the **PostRefiner** utility and apply a large B-factor to these volumes.

However, do keep in mind that these volumes are truncated and the final resolution can be obtained only after running a local refinement on the respective substack of particles (see below).

|||NEWLINE|||

To apply a B-factor on these volumes, click the button ***PostRefiner (Single Map)*** in the middle and fill out the following fields:

|||FIGUREGUI|||09\_gui\_ref\_single.png|||FIGUREGUIEND|||

|||ITEMIZEGUI|||

|||ITEM||| **Input volume pattern:** Sort3D/vol\_cluster\*.hdf

|||ITEMNOTE|||

Click the ***Select HDF Volume*** button, and use the file browser to select a cluster volume.

Then, replace the variable part of the file name with the wildcard character “\*”.

The program will batch process all cluster volumes using the settings below.

|||ITEMNOTEEND|||

|||ITEM||| **Output directory:** Sort3D-sharpened-volumes

|||ITEM||| **Pixel size \[A\]:** 1.14

|||ITEM||| **3D mask file:** 3DMask/sp\_mask\_mask.hdf

|||ITEMNOTE|||

This is the global mask used for the sorting procedure.

|||ITEMNOTEEND|||

|||ITEM||| **Apply adaptive mask:** NO

|||ITEM||| **MTF file:** none

|||ITEM||| **B-factor enhancement:** 450

|||ITEMTIP|||

The choice of B-factor is somewhat arbitrary, since enhanced maps are only used for a visual assessment of the sorting outcomes to allow users to decide which, if any, groups should be subjected to subsequent local refinement.

The value of B-factor should be adjusted using visual inspection of the outcome. The enhanced map should retain “structural integrity” and the histogram of densities should have an “ice peak” (routinely set to zero by the reconstruction program) at about 0.25 of the histogram range.

|||ITEMTIPEND|||

|||ITEM||| **Low-pass filter frequency \[A\]:** 6

|||ITEMNOTE|||

This should be resolution used by the **SORT3D** program.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Start the **PostRefiner (Single Map)** job by clicking the ***Run command*** button.

|||NOTE|||

This step (and **SORT3D** in general) does not output any resolution values or |||FSC||| curves.

|||NOTEEND|||

Display the resulting maps with **UCSF Chimera**.

|||FIGUREMEDIUM|||09\_post\_single.png|||FIGUREMEDIUMEND|||

At first glance, the maps appear similar.

Now use **UCSF Chimera**’s **Morph Map** utility to compare them.

|||FIGUREMEDIUM|||09\_post\_morph-01.png|||FIGUREMEDIUMEND|||

In the morphed structures, we observe a rather quasi-continuous but clear flexibility of several domains of the protein. The flexibility is localized in the upper-region of the complex: the TcB-binding site and adjacent domains.

Further studies revealed that the binding of the component TcB to TcA and the formation of the holotoxin complex stabilizes this structural region.

However, such an in-depth analysis of such heterogeneity requires however a much larger dataset and would therefore be beyond the scope of this tutorial.

|||NEWLINE|||

Keep in mind that the orientation parameters used during sorting relate the individual particle images to the average structure, and consequently, due to superposition of different conformers, the fine details might not be fully resolved at this point.

Therefore, the full potential and resolution limit of each determined group can only be revealed after within-group 3D local refinement (see next section \\nameref{Local Subset Refinement and Final Reconstruction}).

|||NEWLINE|||

However, we usually perform a local refinement only for groups whose visual appearance promises delivery of interesting (and biologically interpretable) results.

This is the basic outline and, needless to say, the procedure can be more complex in practice. For example, sorting may be applied again within selected groups after their local refinement.

In addition, we expect users to compute and analyze 3D variability maps at all stages as well as continuously examine the results of statistical tests done by **SORT3D** in order to avoid accepting any chance groups.

|||NEWLINE|||

To complete the protocol, it is necessary to use **MERIDIEN** in the local mode to perform a local refinement of all groups of interest independently with the possible additional gain of improved resolution, as now the data subsets have improved homogeneity.

|||TIP|||

If **SORT3D** reveals large conformational changes, every group should be refined independently, and in this case you might additionally want to consider starting the **MERIDIEN** runs of each group with exhaustive searches (mode 1) (instead using the local search mode).

|||TIPEND|||

Now, we will create virtual “clean” particle stacks for each sorted cluster that will contain only the particles with IDs included in **Cluster\_|||REDNUM|||ITERNR|||REDNUMEND|||.txt** files produced by **SORT3D**.

|||TIP|||

It is advisable to verify at this point that the stack header is properly populated with the orientation parameters of the **MERIDIEN** run. At the terminal, type:

|||TERMINAL|||

sp\_header.py bdb:Substack\#isac\_substack --params=xform.projection\\\\ --export=try\_orientation\_parameters.txt

|||TERMINALEND|||

Should the command crash or produce an empty text file, there are no parameters in the input stack and one should carefully check all the steps of the analysis to find out what went wrong.

The parameters should have been imported after **MERIDIEN** run was completed and **SORT3D** was initialized using the ***Import Projection Parameters*** tool.

|||TIPEND|||

In the main window of the |||SPHIRE||| |||GUI||| click the button ***SORT3D*** and then the\\\\ ***SORT3D\_DEPTH Stack Subset*** in the middle:

|||FIGUREGUI|||09\_stack\_subset.png|||FIGUREGUIEND|||

Next, fill out the following input fields:

|||ITEMIZEGUI|||

|||ITEM||| **Output stack subset:** bdb:Substack\#sort3d\_substack\_000

|||ITEM||| **Original image stack:** bdb:Substack\#isac\_substack

|||ITEMNOTE|||

Click the ***Select BDB image stack*** button, and use the file browser to select in the **Substack** folder the virtual stack used as input for the previous **SORT3D** run.

|||ITEMNOTEEND|||

|||ITEM||| **Image selection file:** Sort3D/Cluster\_000.txt

|||ITEMNOTE|||

Click the ***Select image list*** button, and use the file browser to select the file with the ID values of all particles accounted for by **SORT3D**.

|||ITEMNOTEEND|||

Click the ***Run command*** button.

|||NEWLINE|||

This will create a virtual stack containing all particles of **Cluster\_000.txt**.

|||TIP|||

The above command has to be **repeated for all groups we intend to do an independent local refinement on**.

One has to input the selected **Cluster\_|||REDNUM|||ITERNR|||REDNUMEND|||.txt** files and set the number **bdb:Substack\#sort3d\_substack\_|||REDNUM|||ITERNR|||REDNUMEND|||** accordingly.

For the results described here, one should create two different substacks.

|||ITEMIZEDASH|||

|||ITEM||| bdb:Substack\#sort3d\_substack\_000

|||ITEM||| bdb:Substack\#sort3d\_substack\_001

|||ITEMIZEDASHEND|||

After the job has finished, you can verify the number of particles in the resulting stack using **EMAN2**’s **e2iminfo.py** command.

At the terminal, type:

|||TERMINAL|||

e2iminfo.py bdb:Substack\#sort3d\_substack\_000

|||NEWLINE|||

e2iminfo.py bdb:Substack\#sort3d\_substack\_001

|||NEWLINE|||

|||TERMINALEND|||

The substacks in the precalculated results contain 6363 and 3929 particles, respectively.

|||TIPEND|||

|||ITEMIZEGUIEND|||

|||SECTION|||Local Subset Refinement and Final Reconstruction|||SECTIONEND|||

The group substacks created in the previous section contain 3D orientation parameters (recall: these were imported to the full stack at the beginning of the sorting protocol, and thus will be inherited by any virtual substack derived from it), and consequently have already the correct format to serve as inputs for a local 3D refinement by **MERIDIEN**.

|||NEWLINE|||

In the main window of the |||SPHIRE||| |||GUI||| click the button ***SORT3D*** on the left and then the ***Local Refinement from Stack*** in the middle and fill out the following input fields:

|||FIGUREGUI|||09\_gui\_local\_ref.png|||FIGUREGUIEND|||

|||ITEMIZEGUI|||

|||ITEM||| **Input image stack:** bdb:Substack\#sort3d\_substack\_000

|||ITEMNOTE|||

Click the ***Select BDB image stack*** button, and use the file browser to select the substack created after **SORT3D**.

|||ITEMNOTEEND|||

|||ITEM||| **Output directory:** Refine3D-Substack-Local\_000

|||ITEM||| **Starting resolution \[A\]:** 8.0

|||ITEMNOTE|||

Enter the resolution that the program is likely to estimate using the provided initial orientation parameters.

The starting resolution here has only a limited impact on the refinement process and it is only used to accelerate the initial 3D reconstruction, the size of which will be limited in order to correspond to the resolution given.

If the parameter is omitted, the program will compute full size half-maps to estimate initial resolution. This is time consuming and is in general unnecessary.

|||ITEMNOTEEND|||

|||ITEM||| **Initial angular sampling step \[Degrees\]:** 2.0

|||ITEMNOTE|||

The initial angular step has to be smaller than |||SI|||3.75 degree|||SIEND|||.

|||ITEMNOTEEND|||

|||ITEM||| **Particle radius \[Pixels\]:** 145

|||ITEM||| **3D mask file:** 3DMask/sp\_mask\_mask.hdf

|||ITEMNOTE|||

Click the ***Select HDF volume*** button, and use the file browser to select the soft-edge 3D mask used during the refinement step.

However, if the 3D sorting reveals large conformational changes, you should create a different mask from each **SORT3D** volume to be used as a reference for the local refinement.

For this purpose, you can use the ***Adaptive*** ***3D*** ***Mask*** utility.

|||ITEMNOTEEND|||

|||ITEM||| **Point-group symmetry:** C5

|||ITEMNOTE|||

The initial angular step has to be smaller than |||SI|||3.75 degree|||SIEND|||.

|||ITEMNOTEEND|||

|||ITEM||| **Memory per node \[GB\]:** 100

|||ITEMIZEGUIEND|||

Advanced parameters:

|||ITEMIZEGUI|||

|||ITEM||| **Search range \[Pixels\]:** 2.25

|||ITEM||| **Search step size \[Pixels\]:** 1.1

|||ITEMNOTE|||

The values of the sampling parameters above depend on many factors, such as the resolution of the initial structure, the kind of refinement that was already performed, where the orientation parameters originated from and, importantly, the goal of the local refinement to be performed.

Therefore, we cannot provide default values and it is more than likely that you will have to experiment with different initial settings and adjust them based on the performance of the program and the quality of the result. As a rule of thumb, the initial angular step and search range should be |||SI|||1.5 |||TIMES||||||SIEND||| of the values of the **MERIDIEN** iteration used as an input to **SORT3D**.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Specify the number of processors (we used 48) and submit the job to the queuing system of the cluster using an appropriate submission script by clicking the ***Run command*** button.

|||NEWLINE|||

Monitor the progress of the job as discussed in the standard 3D refinement section.

On our cluster, this job with 48 processors finished in about |||SI|||3 hours|||SIEND|||.

|||NEWLINE|||

However, if there is no time to wait for the results, copy the precalculated results to the **project directory**.

|||TERMINAL|||

cp -Rp SphireDemoResults/Refine3D-Substack-Local\_\* ./

|||TERMINALEND|||

|||NOTE|||

The above local refinement has to be done for all selected groups.

In this case we will refine all 2 groups.

Please change the **Input file stack** name and **do not forget** to change the **Output directory** name accordingly.

If you have sufficient computational resources, you can run all local refinements simultaneously.

|||NOTEEND|||

Once the two local refinements are completed, we apply the **PostRefiner** tool to obtain the power-spectrum adjusted map and report the final resolution of the local refinement.

Again, this step has to be done independently for each refined group.

|||NEWLINE|||

In the main window of the |||SPHIRE||| |||GUI||| click the **SORT3D** button and then\\\\ **PostRefiner** button in the middle.

|||ENUMERATE|||

|||ITEM||| Specify the two final half maps (\\\\**Refine3D-Substack-Local\_000/vol\_0\_unfil\_|||REDNUM|||ITERNR|||REDNUMEND|||.hdf**\\\\ and\\\\ **Refine3D-Substack-Local\_000/vol\_1\_unfil\_|||REDNUM|||ITERNR|||REDNUMEND|||.hdf**).

|||ITEM||| Define **Sharpening-after-Meridien-Substack-Local\_000** as output directory for **PostRefiner** results of local refinement of **Cluster\_000.txt**.

|||ITEM||| Activate the **Apply adaptive mask** Flag.

|||ITEM||| Set the appropriate **Adaptive mask threshold** for the adaptive mask.

|||ITEM||| Use the exact same parameters as in the previous run of **PostRefiner**.

|||ITEM||| Click the ***Run command*** button.

|||ENUMERATEEND|||

Monitor the progress of the job at the terminal through the logfile **log.txt**:

|||TERMINAL|||

tail -f Sharpening-after-Meridien-Substack-Local\_000/log.txt

|||TERMINALEND|||

|||STDOUT|||

2019-05-23 17:16:10 logLine =\> ---------- \>\>\> Summary \<\<\<------------

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> Final resolution 0.5/0.143 is 4.61/ 3.86\[A\]

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> B-factor is -58.65\[A^2\]

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> FSC curves are saved in halves.txt, full.txt, masked\_halves.txt, masked\_full.txt

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> The final volume is Sharpening-after-Meridien-Substack-Local\_000 /vol\_combined.hdf

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> Guinierlines in logscale are saved in Sharpening-after-Meridien-Substack-Local\_000 /guinierlines.txt

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> Tanl low-pass filter is applied using cutoff frequency 1/ 3.86\[1/A\]

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> ----\>\>\> Analysis of enhancement \<\<\<-----

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> B\_factor : 58.650948

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> Low-pass filter cutoff : 3.858461\[A\] (0.295455\[absolute\])

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> Low-pass filter falloff : 0.010000\[absolute\]

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> Max enhancement point : 102\[pixels\]

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> Max enhancement ratio : 26.232149

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> First zero pw spectrum point : 117\[pixels\]

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> Falloff width : 15\[pixels\]

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> -------------------------------------------------------

|||NEWLINE|||

2019-05-23 17:16:10 logLine =\> ---------- \>\>\> DONE \<\<\< ------------

|||NEWLINE|||

|||STDOUTEND|||

Now check the final |||FSC||| plot.

|||FIGUREMEDIUM|||09\_fsc.png|||FIGUREMEDIUMEND|||

The resolution of locally refined group 000 is |||SI|||3.85 angstrom|||SIEND||| according to |||FSC|||@0.143 between the two masked half-maps.

|||NEWLINE|||

Now run the **PostRefiner** tool for the remaining group and check the respective output file.

For the precalculated results, the reported resolution of the two groups 6363 and 3929 particles is |||SI|||3.85 angstrom|||SIEND||| and |||SI|||4.4 angstrom|||SIEND|||, respectively.

|||NEWLINE|||

In our example, although we improved the homogeneity of each substack by 3D clustering, the achieved resolution after local refinement is rather limited by the low number of particles.

|||NEWLINE|||

You can now display the maps with **UCSF** **Chimera**, morph them and compare them with the available X-ray structure.

However, due to the localized continuous heterogeneity, detailed analysis of this flexibility at near-atomic resolution level of detail would require a much larger dataset.

|||CHAPTERGREY|||Advanced Refinement|||CHAPTERLOCAL|||

|||SECTION|||CTF Refinement|||SECTIONEND|||

Accurate estimation of the CTF is very critical for high-resolution 3D refinement. Using the highest resolution reconstruction achieved so far as reference (3D refinement with the “clean” particle stack after 2D clustering), we will refine the defocus of each particle in the respective stack and repeat the refinement.

|||TIP|||

If the resolution of your map is worse than |||SI|||4.5 angstrom|||SIEND|||, CTF refinement will most probably not make a significant difference.

|||TIPEND|||

In the main window of the |||SPHIRE||| |||GUI||| first click the button ***CTF*** on the left and then the **CTF refine (Stack)** button in the middle (Utilities).

Fill out the following fields:

|||ITEMIZEGUI|||

|||ITEM||| **Input stack path:** bdb:Substack\#isac\_substack

|||ITEMNOTE|||

Click the ***Select BDB Image stack*** button, and use the file browser to select the particle stack.

|||ITEMNOTEEND|||

|||ITEM||| **Output directory:** Substack\_CTF

|||ITEM||| **Path to volume:** Sharpening-after-meridien/vol\_combined.hdf

|||ITEMNOTE|||

Click the ***Select HDF volume*** button, and use the file browser to select the sharpened, masked 3D volume obtained after sharpening.

|||ITEMNOTEEND|||

|||ITEM||| **Params file:** Refine3D/final\_params\_035.txt

|||ITEMNOTE|||

Click the ***Select parameters text*** button, and use the file browser to select the projection parameters file.

|||ITEMNOTEEND|||

|||IMPORTANT|||

Do not combine the results from different refinements.

|||IMPORTANTEND|||

|||ITEMIZEGUIEND|||

Submit the job to the queuing system of the cluster using an appropriate submission script by clicking the ***Run command*** button.

|||NEWLINE|||

Monitor the progress of the job through the standard output.

At the terminal, type:

|||TERMINAL|||

tail -f ctf\_refine\_manual\_logfile

|||TERMINALEND|||

|||STDOUT|||

\#\#\#\#Start refinement\#\#\#\#

|||NEWLINE|||

41%|\#\#\#\#1 | 45/109 \[09:41\<13:35, 12.74s/it\]%

|||STDOUTEND|||

|||NEWLINE|||

On our cluster, this job (single process) finished in about |||SI|||30 minutes|||SIEND|||.

In the output directory Substack\_CTF , you can find following files:

|||ITEMIZEDASH|||

|||ITEM||| **bdb:ctf\_refined:** this is a new stack, containing CTF-refined particles

|||ITEM||| **Statistics:** a folder containing additional information about the CTF Refinement.

|||ITEMIZEDASHEND|||

|||NEWLINE|||

Within the Statistics/img subdirectory, you can find figures summarizing the statistics of the CTF refinement for each micrograph.

|||FIGUREMEDIUM|||10\_ctf.png|||FIGUREMEDIUMEND|||

Each image contains four plots:

|||ITEMIZEDASH|||

|||ITEM||| **Defocus map**: Each dot is a particle while the color represents the estimated defocus value. If your come from a tilted micrograph, you should see a color gradient.

|||ITEM||| **Error map:** The color represents the estimated error in terms of standard deviation of the estimated defocus values. We consider an error below 0.05 micrometer as low.

|||ITEM||| **Significance map:** Here the color represents the ratio of the difference between the old and the new defocus value divided by the estimated error.

|||ITEM||| **Histogram:** The distribution of the refined defocus value for the selected micrographs. The dashed vertical line highlights the previous average defocus value.

|||ITEMIZEDASHEND|||

We will now use the CTF refined particle stack as the input to start a new round of 3D refinement.

In the main window of the |||SPHIRE||| |||GUI||| click the button ***MERIDIEN*** on the left and then the ***3D REFINEMENT*** button in the middle and fill out the following input fields:

|||FIGUREGUI|||10\_gui\_refine\_ctf.png|||FIGUREGUIEND|||

|||ITEMIZEGUI|||

|||ITEM||| **Input image stack:** bdb:Substack\_CTF\#ctf\_refined

|||ITEMNOTE|||

Click the ***Select BDB image stack*** button, and use the file browser to select the ctf refined subset of particles

|||ITEMNOTEEND|||

|||ITEM||| **Output directory:** Refine3D\_CTF

|||ITEM||| **Initial 3D reference:** Sharpening-after-meridien/vol\_combined.hdf

|||ITEMNOTE|||

Click the ***Select HDF volume*** button, and use the file browser to select the |||SI|||3.4 angstrom|||SIEND||| masked, sharpened density map, obtained using the PostRefiner tool.

|||ITEMNOTEEND|||

|||ITEM||| **Read shifts from header:** YES

|||ITEM||| **Starting resolution \[A\]:** 8

|||ITEMNOTE|||

The initial reference is a near-atomic resolution structure obtained by processing these data using a reference-free approach. There is no significant risk for model bias in this case and therefore, we will not apply a very strong low-pass filter to the reference volume.

|||ITEMNOTEEND|||

|||ITEM||| **Initial angular sampling step \[Degrees\]:** 3.75

|||ITEMNOTE|||

We will reduce the sampling step from 7.5|||UNIT|||degree|||UNITEND||| to 3.75|||UNIT|||degree|||UNITEND|||. The refinement of symmetric initial models with high resolution symmetry may benefit from a smaller initial angular sampling step.

|||ITEMNOTEEND|||

|||ITEM||| **Particle radius \[Pixels\]:** 145

|||ITEM||| **3D mask:** Sharpening-after-meridien/vol\_adaptive\_mask.hdf

|||ITEMNOTE|||

This is the 3D mask automatically produced by the PostRefiner tool.

|||ITEMNOTEEND|||

|||ITEM||| **Point-group symmetry:** C5

|||ITEM||| **Memory per node \[GB\]:** 120

|||ITEMIZEGUIEND|||

Specify the number of processors and submit the job to the queuing system of the cluster using an appropriate submission script by clicking the ***Run command*** button.

On our cluster, this job with 64 processes finished in about |||SI|||3 hours|||SIEND||| and |||SI|||30 minutes|||SIEND|||

Now run the PostRefiner and check if CTF Refinement improved the resulting density map.

In the main window of the |||SPHIRE||| |||GUI||| click the button ***MERIDIEN*** on the left and then the ***PostRefiner*** button in the middle and fill out the following input fields:

|||FIGUREGUI|||08\_gui\_post\_refine.png|||FIGUREGUIEND|||

|||ITEMIZEGUI|||

|||ITEM||| **First unfiltered halfset volume:** Refine3D\_CTF/vol\_0\_unfil\_031.hdf

|||ITEM||| **Second unfiltered halfset volume:** Refine3D\_CTF/vol\_1\_unfil\_031.hdf

|||ITEM||| **Output directory:** Sharpening-after-meridien\_CTF

|||ITEM||| **Pixel size \[A\]:** 1.14

|||ITEM||| **3D mask file:** none

|||ITEM||| **Apply adaptive mask**: YES

|||ITEM||| **Binarization threshold:** 0.04

|||ITEM||| **Soft edge width \[Pixels\]:** 5

|||ITEM||| **Dilation width \[Pixels\]:** 3

|||ITEM||| **|||MTF||| file:** FalconIImtf.txt

|||ITEM||| **B-Factor enhancement:** 0

|||ITEM||| **Low-pass filter frequency \[A\]:** 0

|||ITEMIZEGUIEND|||

Click the ***Run command*** button.

|||NEWLINE|||

and monitor the progress of the job at the terminal through the logfile **log.txt**:

|||STDOUT|||

2019-05-20 10:16:32 logLine =\> ----\>\>\> Analysis of enhancement \<\<\<-----

|||NEWLINE|||

2019-05-20 10:16:32 logLine =\> B\_factor : 56.616364

|||NEWLINE|||

2019-05-20 10:16:32 logLine =\> Low-pass filter cutoff : 3.459310\[A\]

|||NEWLINE|||

2019-05-20 10:16:32 logLine =\> Low-pass filter falloff : 0.010000

|||NEWLINE|||

2019-05-20 10:16:32 logLine =\> Max enhancement point : 114\[pixels\]

|||NEWLINE|||

2019-05-20 10:16:32 logLine =\> Max enhancement ratio : 33.879259

|||NEWLINE|||

2019-05-20 10:16:32 logLine =\> First zero pw spectrum point : 131\[pixels\]

|||NEWLINE|||

2019-05-20 10:16:32 logLine =\> Falloff width : 17\[pixels\]

|||STDOUTEND|||

In this case, the CTF Refinement did not have a significant effect on the final resolution in this particular case, most likely due to the very limited number of particles.

|||CHAPTERRED|||LOCALRES|||CHAPTERLOCAL|||

|||SECTION|||Local Resolution|||SECTIONEND|||

To interpret a |||CRYO-EM||| density map properly, it is necessary to know the resolution to which the reliable structural information extends.

The highest resolution we achieved so far was |||SI|||3.4 angstrom|||SIEND||| |||FSC|||@0.143, and was obtained after 3D refinement, using a dataset cleaned in 2D by **ISAC2**.

This value, however, represents an average resolution for the entire map.

In addition, due to the intrinsic flexibility, as revealed by 3D clustering using **SORT3D**, and image processing artifacts, the resolution is likely to vary locally.

Using the **LOCALRES** tool, we will now compute the local resolution of our final map.

|||NEWLINE|||

In the main window of the |||SPHIRE||| |||GUI||| click the button ***LOCALRES*** on the left and then the ***Local Resolution*** button in the middle.

|||FIGUREGUI|||10\_gui\_local\_res.png|||FIGUREGUIEND|||

Fill out the following fields:

|||ITEMIZEGUI|||

|||ITEM||| **First half-volume:** Refine3D/vol\_0\_unfil\_032.hdf

|||ITEMNOTE|||

Click the ***Select HDF volume*** button, and use the file browser to select the first final half-volumes.

|||ITEMNOTEEND|||

|||ITEM||| **Second half-volume:** Refine3D/vol\_1\_unfil\_032.hdf

|||ITEMNOTE|||

Click the ***Select HDF volume*** button, and use the file browser to select the second final half-volumes.

|||ITEMNOTEEND|||

|||ITEM||| **3D mask:** Sharpening-after-meridien/vol\_adaptive\_mask.hdf

|||ITEMNOTE|||

Click the ***Select HDF volume*** button, and use the file browser to select the soft-edge 3D mask obtained in the **PostRefiner** step.

|||ITEMNOTEEND|||

|||ITEMNOTE|||

Voxels of the output local resolution volume are assigned a resolution value (in absolute frequency units).

The analysis will be restricted to the voxels within the region outlines by the mask.

This will speed up the process.

|||ITEMNOTEEND|||

|||ITEM||| **Output Directory:** LocalRes

|||ITEM||| **Window size \[Pixels\]:** 7

|||ITEMNOTE|||

Real space |||FSC||| will be performed within small window areas.

This parameter defines their size in pixels.

The correct size depends on the resolution of the map.

Setting the window size too small will result in inaccurate estimations that will vary widely from location to location, whereas too large windows will produce a coarsely sampled resolution map, that most likely will not reflect local resolution variations sufficiently well.

We usually use a window size of |||SI|||7 angstrom|||SIEND||| to |||SI|||10 angstrom|||SIEND|||.

As an example, if the resolution of a map is |||SI|||7 angstrom|||SIEND||| and the pixel size is |||SI|||1 angstrom|||SIEND|||, the window size should be at least |||SI|||7 pixels|||SIEND|||.

For a map with nominal resolution of |||SI|||12 angstrom|||SIEND||| and pixel size |||SI|||2 angstrom|||SIEND|||, the window size should be at least |||SI|||5 pixels|||SIEND|||.

|||ITEMNOTEEND|||

|||ITEM||| **Fourier shell step size \[Pixels\]:** 2

|||ITEMNOTE|||

Thickness of the Fourier shell used to focus the resolution estimation in reciprocal space.

Setting a larger step size will speed up the process, but also produce a less precise resolution map.

Using a small window size might result in inaccurate and usually underestimated |||FSC||| values.

|||ITEMNOTEEND|||

|||ITEM||| **Save Angstrom local resolution:** YES

|||ITEMNOTE|||

By default, the program produces a local resolution map with resolution values given in absolute frequency units.

Activate this option to obtain a second local resolution map with resolution values given in |||UNIT|||angstrom|||UNITEND|||.

This map is usually used only for visualization in Chimera (see section below).

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Specify the number of processors and submit the job to the queuing system of the cluster using an appropriate submission script by clicking the ***Run command*** button.

|||NEWLINE|||

On our cluster, this job with 96 processors finished in about |||SI|||2 minutes|||SIEND|||.

|||NEWLINE|||

Load the resulting |||UNIT|||angstrom|||UNITEND|||ngstrom resolution volume (**localres\_ang.hdf**) and the sharpened map (**Sharpening-after-meridien/vol\_combined.hdf**) into **UCSF Chimera**.

Open the **Surface Color** tool available in **UCSF Chimera**.

|||FIGURESMALL|||11\_chimera\_local.png|||FIGURESMALLEND|||

|||ITEMIZEDASH|||

|||ITEM||| |||REDNUM|||(1)|||REDNUMEND||| Click the **Options Button**.

Color surface of volume: **vol\_combined.hdf**.

|||ITEM||| |||REDNUM|||(2)|||REDNUMEND||| By volume data value.

|||ITEM||| |||REDNUM|||(3)|||REDNUMEND||| of volume file **localres.hdf**.

|||ITEM||| |||REDNUM|||(4)|||REDNUMEND||| Set number of colors to 10.

Select the **Palette Rainbow**.

|||ITEM||| |||REDNUM|||(5)|||REDNUMEND||| Click the **Set** button.

|||ITEM||| |||REDNUM|||(6)|||REDNUMEND||| and then the **Color** button.

|||ITEMIZEDASHEND|||

|||FIGUREMEDIUM|||11\_local\_res.png|||FIGUREMEDIUMEND|||

|||TIP|||

We strongly recommend comparing the local resolution results with the 3D variability map and the 3D clustering results, obtained in the previous sections.

|||TIPEND|||

|||TIP|||

The values are given in **absolute frequency** units. You can also use the **localres\_ang.hdf** map to color the volume (|||REDNUM|||(3)|||REDNUMEND||| ) with values in |||SI||| angstrom|||SIEND|||. The distribution of the individual resolution values should match the level of detail of the |||CRYO-EM||| density map.

|||TIPEND|||

However, if you do not have enough time, you can copy the precalculated local resolution map to the **project directory**.

|||TERMINAL|||

cp -Rp SphireDemoResults/LOCALRES ./

|||TERMINALEND|||

|||SECTION|||Local Filtering|||SECTIONEND|||

After calculating the local resolution map of our final structure, we will now filter the map accordingly.

A locally filtered map is more suitable for interpretation and can be used for further analysis (i.e., model building) without the risk of over-interpreting individual features.

Poorly resolved regions (corresponding to flexible domains) will be filtered to their respective local resolutions and not to the average (higher) resolution.

Similarly, regions better resolved than the average will not be suppressed and local filtering might allow improved molecular modeling in these regions.

|||NEWLINE|||

However, before applying the local filter, we need to re-run the **PostRefiner** step in order to obtain a masked, sharpened, but **unfiltered** map (the previous map was filtered to the average resolution according to the |||FSC|||@0.143).

|||NEWLINE|||

In the main window of the |||SPHIRE||| |||GUI||| click the button ***MERIDIEN*** and then the\\\\ ***PostRefiner*** button in the middle.

|||FIGUREGUI|||11\_gui\_post\_local.png|||FIGUREGUIEND|||

Fill out the following fields:

|||ITEMIZEGUI|||

|||ITEM||| **First unfiltered halfset volume:** Refine3D/vol\_0\_unfil\_032.hdf

|||ITEM||| **Second unfiltered halfset volume:** Refine3D/vol\_1\_unfil\_032.hdf

|||ITEM||| **Output directory:** Sharpening-after-meridien\_nofilter

|||ITEM||| **3D mask file:** none

|||ITEM||| **Apply adaptive mask:** YES

|||ITEM||| **MTF file:** FalconIImtf.txt

|||ITEM||| **B-factor enhancement:** 0

|||ITEM||| **Low-pass filter frequency \[A\]:** -1

|||ITEMNOTE|||

\-1 means no low-pass filtration.

|||ITEMNOTEEND|||

|||ITEMIZEGUIEND|||

Monitor the progress of the **PostRefiner** job at the terminal through the logfile **log.txt**:

|||TERMINAL|||

tail -f Sharpening-after-meridien\_nofilter/log.txt

|||TERMINALEND|||

The output will look like this:

|||STDOUT|||

2019-05-20 14:49:04 logLine =\> ---------- \>\>\> Summary \<\<\<------------

|||NEWLINE|||

2019-05-20 14:49:04 logLine =\> Final resolution 0.5/0.143 is 4.14/ 3.43\[A\]

|||NEWLINE|||

2019-05-20 14:49:04 logLine =\> B-factor is -56.03\[A^2\]

|||NEWLINE|||

2019-05-20 14:49:04 logLine =\> FSC curves are saved in halves.txt, full.txt, masked\_halves.txt, masked\_full.txt

|||NEWLINE|||

2019-05-20 14:49:04 logLine =\> The final volume is Sharpening-after-meridien\_nofilter/vol\_combined.hdf

|||NEWLINE|||

2019-05-20 14:49:04 logLine =\> Guinierlines in logscale are saved in Sharpening-after-meridien\_nofilter/guinierlines.txt

|||NEWLINE|||

2019-05-20 14:49:04 logLine =\> **The final volume is not low-pass filtered.**

|||NEWLINE|||

2019-05-20 14:49:04 logLine =\> -------------------------------------------------------

2019-05-20 14:49:04 logLine =\> ---------- \>\>\> DONE \<\<\< ------------

2019-05-20 14:49:04 logLine =\> --------------------------------------------------------------------------------------------

|||STDOUTEND|||

Now we will apply the local filter to the output volume\\\\ (**Sharpening-after-meridien\_nofilter/vol\_combined.hdf**).

|||NEWLINE|||

In the main window of the |||SPHIRE||| |||GUI||| click the button ***LOCALRES*** and then the ***3D Local Filter*** button in the middle.

|||FIGUREGUI|||10\_local\_filter.png|||FIGUREGUIEND|||

Set the following input fields:

|||ITEMIZEGUI|||

|||ITEM||| **Input volume:** Sharpening-after-meridien\_nofilter/vol\_combined.hdf

|||ITEMNOTE|||

Click the ***Select HDF volume*** button, and use the file browser to select the sharpened but unfiltered map created in the previous step.

|||ITEMNOTEEND|||

|||ITEM||| **Local resolution file:** LocalRes/localres.hdf

|||ITEMNOTE|||

Click the ***Select HDF volume*** button, and use the file browser to select the local resolution volume with resolution values given in **absolute frequency** units.

Do **not** use here the localres\_ang.hdf file here (local resolution volume with resolution values in Å.

|||ITEMNOTEEND|||

|||ITEM||| **3D mask:** Sharpening-after-meridien\_nofilter/vol\_adaptive\_mask.hdf

|||ITEMNOTE|||

Click the ***Select HDF volume*** button, and use the file browser to select the soft-edge 3D mask obtained in the previous step.

|||ITEMNOTEEND|||

|||ITEM||| **Output volume:** FINAL-VOLUME.hdf

|||ITEMIZEGUIEND|||

Specify the number of processors (for this job we used 48), and submit the job to the queuing system of the cluster using an appropriate submission script by clicking the ***Run command*** button.

|||NEWLINE|||

On our cluster this job finished in about |||SI|||3 minutes|||SIEND|||.

|||NEWLINE|||

Display the final map with **UCSF Chimera**.

Compare the density with the available X-ray structure.

|||FIGURESMALL|||final.png|||FIGURESMALLEND|||

|||CENTER|||

\\Huge{**Congratulations\!**}

|||NEWLINE|||

You have finished the tutorial successfully.

|||NEWLINE|||

Now it is time to process your own data.

|||CENTEREND|||
